import pyaudio
import webrtcvad
import time
from aip import AipSpeech

# ç™¾åº¦api
APP_ID = ''
API_KEY = '' 
SECRET_KEY = ''

client = AipSpeech(APP_ID, API_KEY, SECRET_KEY)

class ASRhelper:
    def __init__(self):
        # è®¾ç½®éŸ³é¢‘å‚æ•°
        self.CHUNK = 480  
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.RATE = 16000
        self.SILENCE_DURATION = 1.0  
        self.MAX_RECORD_SECONDS = 5  
        self.NO_SPEECH_TIMEOUT = 2.0  
        # self.voice = "zh-CN-XiaoyiNeural"

        self.vad = webrtcvad.Vad(2)  
     
        self.p, self.stream = self.get_audio_stream()

    def get_audio_stream(self):
        """åˆå§‹åŒ–è¾“å…¥éŸ³é¢‘æµ"""
        p = pyaudio.PyAudio()
        stream = p.open(format=self.FORMAT,
                        channels=self.CHANNELS,
                        rate=self.RATE,
                        input=True,
                        frames_per_buffer=self.CHUNK)
        return p, stream

    def real_time_recognition(self):
        """å®æ—¶è¯­éŸ³è¯†åˆ«"""
        # print('*'*40,"å¯ä»¥è¯´è¯å’¯ğŸ˜","*"*40)

        #è¾“å…¥æµ
        input= []
        start_time = time.time()
        speech_started = False
        last_speech_time = time.time()

        while True:
            try:
                data = self.stream.read(self.CHUNK, exception_on_overflow=False)
                is_speech = self.vad.is_speech(data, self.RATE)

                if is_speech:
                    if  speech_started==False:
                        speech_started = True
                        # print('*'*10,"å¯ä»¥è¯´è¯å’¯ğŸ˜","*"*10)
                    last_speech_time = time.time()
                    input.append(data)
                else:
                    if speech_started:

                        if (time.time() - last_speech_time) >= self.SILENCE_DURATION:
                            print('*'*10,"è¯­éŸ³ç»“æŸğŸ™Š",'*'*10)
                            break
                if (time.time() - start_time) >= self.MAX_RECORD_SECONDS:
                    # print("å½•å®Œäº†")
                    break

                if not speech_started and (time.time() - start_time) >= self.NO_SPEECH_TIMEOUT:
                    print("è¯·ä½ æå‡ºé—®é¢˜ï¼ŸğŸ˜¾")
                    start_time = time.time()  # Reset start time

            except Exception as e:
                print("å½•éŸ³æœ‰é”™è¯¯ï¼ï¼ï¼", str(e))
                break

        if input:
            audio_data = b"".join(input)
            print(f"ä¸Šä¼  {len(audio_data)} ä¸ªå­—èŠ‚åˆ°ğŸª°")
            result = client.asr(audio_data, 'pcm', self.RATE, {'dev_pid': 1537})
            if result['err_no'] != 0:
                # print("ğŸ§  ç”¨æˆ·é—®ï¼š:", result['result'][0])

            
                print("âŒ è¯†åˆ«å¤±è´¥:", result['err_msg'], "é”™è¯¯ç :", result['err_no'])
        else:
            print("æ²¡æœ‰å½•åˆ°è¯­éŸ³")
        
        return result

    def stop_recording(self):
        """å…³é—­éŸ³é¢‘æµ"""
        self.stream.stop_stream()
        self.stream.close()
        self.p.terminate()
        print("éŸ³é¢‘æµå·²å…³é—­â€¼ï¸")
    def main(self):
        try:
            self.real_time_recognition()
        except KeyboardInterrupt:
            print("*" * 10, "åœæ­¢å®æ—¶è¯­éŸ³è¯†åˆ«â€¼ï¸","*" * 10)
        finally:
            assistant.stop_recording()

if __name__ == '__main__':
    assistant = ASRhelper()
    assistant.main()