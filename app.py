import sys
import asyncio
import time
from PySide6.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout, 
                           QHBoxLayout, QLabel, QTextEdit, QFrame, QScrollArea,
                           QPushButton, QFileDialog)
from PySide6.QtCore import Qt, QSize, QTimer, Signal, QObject, QEvent
from PySide6.QtGui import QFont, QPalette, QColor, QKeySequence, QIcon, QPixmap, QShortcut
import pyaudio
import webrtcvad
from aip import AipSpeech
import edge_tts
import io
import subprocess
import logging
import re
import json
from datetime import datetime
from collections import deque

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("chat.log"), logging.StreamHandler()]
)

# ç™¾åº¦ASR APIé…ç½®
APP_ID = ''
API_KEY = '' 
SECRET_KEY = ''

# QAæ¨¡å‹æ‰€éœ€å¯¼å…¥
from langchain_community.vectorstores import FAISS
from langchain_core.embeddings import Embeddings
import nest_asyncio
from openai import OpenAI
import random
nest_asyncio.apply()

# ==================================
# å¯¹è¯ç®¡ç†å™¨ç±» (ä»conversation.py)
# ==================================
class ConversationManager:
    def __init__(self, max_history=10, tracking_file="conversation_tracking.json"):
        # å¯¹è¯å†å²ç®¡ç†
        self.conversation_history = deque(maxlen=max_history)
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # æ€§èƒ½è·Ÿè¸ªæŒ‡æ ‡
        self.tracking_data = {
            'session_id': self.session_id,
            'user_id': None,
            'start_time': time.time(),
            'total_questions': 0,
            'total_responses': 0,
            'avg_response_time': 0,
            'response_times': [],
            'error_count': 0,
            'conversation_log': []
        }
        
        self.tracking_file = tracking_file
        self._lock = asyncio.Lock()
    
    async def add_conversation_entry(self, question, answer, response_time=None):
        """å¼‚æ­¥æ·»åŠ å¯¹è¯è®°å½•"""
        async with self._lock:
            entry = {
                'timestamp': datetime.now().isoformat(),
                'question': question,
                'answer': answer,
                'response_time': response_time
            }
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            self.conversation_history.append(entry)
            
            # æ›´æ–°è·Ÿè¸ªæ•°æ®
            self.tracking_data['total_questions'] += 1
            self.tracking_data['total_responses'] += 1
            
            if response_time:
                self.tracking_data['response_times'].append(response_time)
                self.tracking_data['avg_response_time'] = sum(self.tracking_data['response_times']) / len(self.tracking_data['response_times'])
            
            # è½»é‡çº§æ—¥å¿—è®°å½•ï¼ˆä»…ä¿å­˜å…³é”®ä¿¡æ¯ï¼‰
            log_entry = {
                'time': datetime.now().strftime("%H:%M:%S"),
                'q': question[:50] + '...' if len(question) > 50 else question,
                'response_time': round(response_time, 2) if response_time else None
            }
            self.tracking_data['conversation_log'].append(log_entry)
    
    async def record_error(self, error_type, error_message):
        """è®°å½•é”™è¯¯ä¿¡æ¯"""
        async with self._lock:
            self.tracking_data['error_count'] += 1
            error_entry = {
                'timestamp': datetime.now().isoformat(),
                'type': error_type,
                'message': str(error_message)[:100]
            }
            
            if 'errors' not in self.tracking_data:
                self.tracking_data['errors'] = []
            self.tracking_data['errors'].append(error_entry)
    
    def get_conversation_context(self, max_context=3):
        """è·å–æœ€è¿‘çš„å¯¹è¯ä¸Šä¸‹æ–‡"""
        recent_conversations = list(self.conversation_history)[-max_context:]
        context = []
        for conv in recent_conversations:
            context.append(f"é—®é¢˜: {conv['question']}")
            context.append(f"å›ç­”: {conv['answer']}")
        return "\n".join(context)
    
    async def save_tracking_data(self):
        """å¼‚æ­¥ä¿å­˜è·Ÿè¸ªæ•°æ®"""
        async with self._lock:
            try:
                with open(self.tracking_file, 'w', encoding='utf-8') as f:
                    json.dump(self.tracking_data, f, ensure_ascii=False, indent=2)
            except Exception as e:
                logging.error(f"ä¿å­˜è·Ÿè¸ªæ•°æ®å¤±è´¥: {e}")
    
    def get_session_summary(self):
        """è·å–ä¼šè¯æ‘˜è¦"""
        duration = time.time() - self.tracking_data['start_time']
        return {
            'session_id': self.session_id,
            'duration': round(duration, 2),
            'total_questions': self.tracking_data['total_questions'],
            'avg_response_time': round(self.tracking_data['avg_response_time'], 2),
            'error_count': self.tracking_data['error_count']
        }

# ==================================
# è¯­éŸ³åˆæˆç±» (ä»tts_stream.py)
# ==================================
class TTSStreamer:
    def __init__(self, voice="zh-CN-XiaoyiNeural", rate="+0%", volume="+0%"):
        self.voice = voice
        self.rate = rate
        self.volume = volume
        self.is_speaking = False
        self._lock = asyncio.Lock()
        self.mpg123_process = None
        self.speech_queue = asyncio.Queue()
        self.speech_task = None
        self._playback_complete = asyncio.Event()
        self._playback_complete.set()  # Initially set
        self._last_audio_time = 0

    def preprocess_text(self, text):
        """é¢„å¤„ç†æ–‡æœ¬ï¼Œä¿ç•™æ›´å¤šåŸå§‹æ ‡ç‚¹ç»“æ„"""
        # åªæ›¿æ¢ä¸­æ–‡æ ‡ç‚¹ä¸ºå¯¹åº”çš„è‹±æ–‡æ ‡ç‚¹ï¼Œä¸å…¨éƒ¨æ›¿æ¢ä¸ºé€—å·
        text = text.replace("ï¼Œ", ",")
        text = text.replace("ã€‚", ".")  # ä¿ç•™å¥å·çš„ç»“æ„
        text = text.replace("ã€", ",")
        text = text.replace("ï¼›", ";")  # ä¿ç•™åˆ†å·
        text = text.replace("ï¼š", ":")  # ä¿ç•™å†’å·
        text = text.replace("ï¼Ÿ", "?")  # ä¿ç•™é—®å·
        text = text.replace("ï¼", "!")  # ä¿ç•™æ„Ÿå¹å·
        text = re.sub(r'[\x00-\x1F\x7F]', '', text)
        return text

    async def start_player(self):
        """å¯åŠ¨mpg123è¿›ç¨‹"""
        async with self._lock:
            if self.mpg123_process is None or self.mpg123_process.poll() is not None:
                try:
                    self.mpg123_process = subprocess.Popen(
                        ["mpg123", "-q", "-"],
                        stdin=subprocess.PIPE,
                        stdout=subprocess.DEVNULL,
                        stderr=subprocess.DEVNULL,
                        bufsize=1024*8
                    )
                    logging.info("mpg123æ’­æ”¾å™¨å·²å¯åŠ¨")
                except Exception as e:
                    logging.error(f"å¯åŠ¨mpg123å¤±è´¥: {e}")
                    self.mpg123_process = None
                    raise

    async def stop_player(self):
        """å®‰å…¨å…³é—­æ’­æ”¾å™¨è¿›ç¨‹"""
        async with self._lock:
            if self.mpg123_process:
                try:
                    self.mpg123_process.stdin.flush()
                    self.mpg123_process.stdin.close()
                    self.mpg123_process.terminate()
                    await asyncio.sleep(0.3)
                    if self.mpg123_process.poll() is None:
                        self.mpg123_process.kill()
                    await asyncio.sleep(0.2)
                    self.mpg123_process = None
                    logging.info("mpg123æ’­æ”¾å™¨å·²å…³é—­")
                except Exception as e:
                    logging.error(f"å…³é—­mpg123æ—¶å‡ºé”™: {e}")

    async def _generate_speech(self, text):
        """ç”Ÿæˆè¯­éŸ³æ•°æ®"""
        if not text or not text.strip():
            return None
            
        try:
            communicate = edge_tts.Communicate(
                text, 
                self.voice,
                rate=self.rate,
                volume=self.volume
            )
            
            audio_data = io.BytesIO()
            
            async for chunk in communicate.stream():
                if chunk["type"] == "audio":
                    audio_data.write(chunk["data"])
                    
            if audio_data.tell() > 0:
                audio_data.seek(0)
                return audio_data.getvalue()
            else:
                return None
        except Exception as e:
            logging.error(f"ç”Ÿæˆè¯­éŸ³æ—¶å‡ºé”™: {e}")
            return None
            
    async def _speech_processor(self):
        """å¤„ç†è¯­éŸ³é˜Ÿåˆ—çš„åå°ä»»åŠ¡ï¼Œä½¿ç”¨ä¼˜åŒ–çš„å»¶è¿Ÿç­–ç•¥"""
        try:
            await self.start_player()
            
            while True:
                text = await self.speech_queue.get()
                
                if text is None:  # ç»“æŸä¿¡å·
                    break
                    
                try:
                    self._playback_complete.clear()
                    self.is_speaking = True
                    
                    audio_data = await self._generate_speech(text)
                    
                    if audio_data:
                        if self.mpg123_process and self.mpg123_process.poll() is None:
                            self.mpg123_process.stdin.write(audio_data)
                            self.mpg123_process.stdin.flush()
                            
                            # ä¼˜åŒ–å»¶è¿Ÿç­–ç•¥ - æ›´å‡†ç¡®çš„ä¼°ç®—
                            text_length = len(text)
                            base_delay = 0.18  
                            min_delay = 0.8    
                            max_delay = 8.0    
                            
                            delay = max(min_delay, min(max_delay, text_length * base_delay))
                            await asyncio.sleep(delay + 0.3)  
                            
                        else:
                            await self.start_player()
                            if self.mpg123_process:
                                self.mpg123_process.stdin.write(audio_data)
                                self.mpg123_process.stdin.flush()
                                
                                text_length = len(text)
                                delay = max(0.8, min(8.0, text_length * 0.12))
                                await asyncio.sleep(delay + 0.3)
                    
                    self._last_audio_time = time.time()
                    
                except Exception as e:
                    logging.error(f"æ’­æ”¾è¯­éŸ³æ—¶å‡ºé”™: {e}")
                
                finally:
                    self.is_speaking = False
                    self._playback_complete.set()
                    self.speech_queue.task_done()
                
        except Exception as e:
            logging.error(f"è¯­éŸ³å¤„ç†ä»»åŠ¡å‡ºé”™: {e}")
        finally:
            await self.stop_player()
            
    async def start_speech_processor(self):
        """å¯åŠ¨è¯­éŸ³å¤„ç†ä»»åŠ¡"""
        if self.speech_task is None or self.speech_task.done():
            self.speech_task = asyncio.create_task(self._speech_processor())
            
    async def stop_speech_processor(self):
        """åœæ­¢è¯­éŸ³å¤„ç†ä»»åŠ¡"""
        if self.speech_task and not self.speech_task.done():
            await self.speech_queue.put(None)
            await self.speech_task
            self.speech_task = None

    async def speak_text(self, text, wait=False):
        """æµå¼å¤„ç†æ–‡æœ¬ï¼Œä½¿ç”¨æ›´æ™ºèƒ½çš„å¥å­åˆ†å‰²"""
        text = self.preprocess_text(text)
        
        # æ™ºèƒ½åˆ†æ®µ - åœ¨è‡ªç„¶æ–­å¥ç‚¹åˆ†å‰²
        segments = []
        # æ ¹æ®å¥å­ç»“æŸæ ‡ç‚¹ï¼ˆå¥å·ã€é—®å·ã€æ„Ÿå¹å·ã€åˆ†å·ï¼‰æˆ–è¾ƒé•¿çš„é€—å·åˆ†å¥è¿›è¡Œåˆ†æ®µ
        sentence_pattern = r'(?<=[.!?;])\s+|(?<=,)\s+(?=\S{5,})'
        parts = re.split(sentence_pattern, text)
        
        max_length = 60  # å¢åŠ æœ€å¤§é•¿åº¦ï¼Œå…è®¸æ›´å®Œæ•´çš„å¥å­
        
        # è¿›ä¸€æ­¥å¤„ç†è¿‡é•¿çš„æ®µè½
        for part in parts:
            if len(part) <= max_length:
                segments.append(part)
            else:
                # å¤„ç†è¿‡é•¿çš„æ®µè½ï¼Œå°è¯•åœ¨é€—å·å¤„åˆ†å‰²
                comma_parts = part.split(',')
                current_segment = ""
                
                for comma_part in comma_parts:
                    if len(current_segment) + len(comma_part) > max_length and current_segment:
                        segments.append(current_segment.strip())
                        current_segment = comma_part
                    else:
                        if current_segment:
                            current_segment += ", " + comma_part
                        else:
                            current_segment = comma_part
                
                if current_segment:
                    segments.append(current_segment.strip())
        
        # å¦‚æœæ²¡æœ‰åˆ†æ®µï¼Œå°±ä½œä¸ºæ•´ä½“
        if not segments:
            segments = [text]
        
        # ç¡®ä¿å¤„ç†å™¨è¿è¡Œ
        await self.start_speech_processor()
        
        # æ’­æ”¾æ‰€æœ‰æ®µè½
        for segment in segments:
            if segment.strip():
                await self.speech_queue.put(segment)
        
        # å¦‚æœéœ€è¦ç­‰å¾…å®Œæˆ
        if wait:
            await self.wait_until_done()

    async def wait_until_done(self):
        """ç­‰å¾…æ‰€æœ‰è¯­éŸ³æ’­æ”¾å®Œæˆ - ä½¿ç”¨æ›´æ™ºèƒ½çš„ç­–ç•¥"""
        # ç­‰å¾…é˜Ÿåˆ—æ¸…ç©º
        if self.speech_queue.qsize() > 0:
            await self.speech_queue.join()
        
        # ç­‰å¾…æœ€åä¸€ä¸ªéŸ³é¢‘æ’­æ”¾å®Œæˆ
        await self._playback_complete.wait()
        
        # å‡å°‘é¢å¤–ç­‰å¾…æ—¶é—´ï¼Œæé«˜å“åº”é€Ÿåº¦
        await asyncio.sleep(0.4)  # ä»1.0å‡å°‘åˆ°0.4ç§’

    async def shutdown(self):
        """æ¸…ç†èµ„æº"""
        await self.stop_speech_processor()
        await self.stop_player()

# ==================================
# è¯­éŸ³è¯†åˆ«ç±» (ä»asr.py)
# ==================================
class ASRHelper:
    def __init__(self):
        # è®¾ç½®éŸ³é¢‘å‚æ•°
        self.CHUNK = 480  # è¯»å–å¸§
        self.FORMAT = pyaudio.paInt16  # ç¬¦åˆç™¾åº¦apiç¼–ç 
        self.CHANNELS = 1  # å•å£°é“
        self.RATE = 16000  # é‡‡æ ·ç‡
        self.SILENCE_DURATION = 1.0  # é™éŸ³æ—¶é•¿
        self.MAX_RECORD_SECONDS = 5  # å½•éŸ³æœ€é•¿æ—¶é—´
        self.NO_SPEECH_TIMEOUT = 2.0  # æ²¡æœ‰è¯­éŸ³çš„è¶…æ—¶æ—¶é—´

        self.vad = webrtcvad.Vad(3)  # è¯­è¨€æ£€æµ‹
        self.client = AipSpeech(APP_ID, API_KEY, SECRET_KEY)
        
        self.p = None
        self.stream = None
        self.is_recording = False
    
    def initialize_audio(self):
        """åˆå§‹åŒ–éŸ³é¢‘æµ"""
        if self.p is None:
            self.p = pyaudio.PyAudio()
        
        if self.stream is None:
            self.stream = self.p.open(
                format=self.FORMAT,
                channels=self.CHANNELS,
                rate=self.RATE,
                input=True,
                frames_per_buffer=self.CHUNK
            )
            
    def close_audio(self):
        """å…³é—­éŸ³é¢‘æµ"""
        if self.stream is not None:
            self.stream.stop_stream()
            self.stream.close()
            self.stream = None
            
        if self.p is not None:
            self.p.terminate()
            self.p = None
            logging.info("éŸ³é¢‘æµå·²å…³é—­")

    async def real_time_recognition(self, callback=None):
        """å®æ—¶è¯­éŸ³è¯†åˆ«ï¼ˆæ ‘è“æ´¾æ¨¡å¼ï¼‰"""
        self.initialize_audio()
        self.is_recording = True
        
        audio_input = []
        start_time = time.time()
        speech_started = False
        last_speech_time = time.time()
        
        # çŠ¶æ€å›è°ƒ
        if callback:
            callback("listening")

        try:
            while self.is_recording:
                data = self.stream.read(self.CHUNK, exception_on_overflow=False)
                is_speech = self.vad.is_speech(data, self.RATE)

                if is_speech:
                    if not speech_started:
                        speech_started = True
                    last_speech_time = time.time()
                    audio_input.append(data)
                else:
                    if speech_started:
                        if (time.time() - last_speech_time) >= self.SILENCE_DURATION:
                            logging.info("è¯­éŸ³ç»“æŸ")
                            break
                            
                if (time.time() - start_time) >= self.MAX_RECORD_SECONDS:
                    logging.info("è¾¾åˆ°æœ€å¤§å½•éŸ³æ—¶é—´")
                    break

                if not speech_started and (time.time() - start_time) >= self.NO_SPEECH_TIMEOUT:
                    if callback:
                        callback("waiting")
                    logging.info("æ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³")
                    return None
                    
                # è®©å‡ºæ§åˆ¶æƒç»™ä¸»äº‹ä»¶å¾ªç¯
                await asyncio.sleep(0.01)
                
        except Exception as e:
            logging.error(f"å½•éŸ³å‡ºé”™: {e}")
            if callback:
                callback("error")
            return None
            
        finally:
            self.is_recording = False
            
        if callback:
            callback("processing")
            
        if audio_input:
            audio_data = b"".join(audio_input)
            logging.info(f"ä¸Šä¼  {len(audio_data)} ä¸ªå­—èŠ‚è¿›è¡Œè¯†åˆ«")
            
            result = await asyncio.to_thread(
                self.client.asr, audio_data, 'pcm', self.RATE, {'dev_pid': 1537}
            )
            
            if result['err_no'] == 0:
                recognized_text = result['result'][0]
                logging.info(f"è¯†åˆ«ç»“æœ: {recognized_text}")
                return recognized_text
            else:
                logging.error(f"è¯†åˆ«å¤±è´¥: {result['err_msg']}, é”™è¯¯ç : {result['err_no']}")
                return None
        else:
            logging.info("æ²¡æœ‰å½•åˆ°è¯­éŸ³")
            return None
    
    def stop_recording(self):
        """åœæ­¢å½•éŸ³"""
        self.is_recording = False

# ==================================
# çŸ¥è¯†é—®ç­”ç±» (ä»qa_model_easy.py)
# ==================================
class LlamaCppEmbeddings(Embeddings):
    """è‡ªå®šä¹‰åµŒå…¥ç±»ï¼Œä½¿ç”¨ llama.cpp åŠ è½½ GGUF æ¨¡å‹ç”ŸæˆåµŒå…¥"""
    def __init__(self, model_path):
        from llama_cpp import Llama
        self.model = Llama(model_path=model_path, embedding=True)
    def embed_documents(self, texts):
        return [self.model.embed(text) for text in texts]
    def embed_query(self, text: str):
        return self.model.embed(text)

class KnowledgeQA:
    def __init__(
        self,
        faiss_index_path="faiss_index",
        temperature=0.3,
        k_documents=3,
        embedding_model_path="model/text2vec_base_chinese_q8.gguf",
        conversation_manager=None
    ):
        self.faiss_index_path = faiss_index_path
        self.k_documents = k_documents
        self.temperature = temperature
        self.embedding_model = LlamaCppEmbeddings(model_path=embedding_model_path)
        self.vectorstore = self._load_vectorstore_with_retry()
        self.unknown_responses = [
            "æˆ‘ä¸çŸ¥é“",
            "è¿™ä¸ªé—®é¢˜æˆ‘æ— æ³•å›ç­”",
            "æŠ±æ­‰æˆ‘ä¸å¤ªä¼š",
            "æˆ‘è¿˜ä¸äº†è§£è¿™æ–¹é¢ã€‚",
            "å¯¹ä¸èµ·ï¼Œæˆ‘æ²¡æœ‰è¿™æ–¹é¢çš„èµ„æ–™ã€‚",
            "æˆ‘ä¸çŸ¥é“è¿™ä¸ªç­”æ¡ˆï¼Œä¸è¿‡ä½ å¯ä»¥å»é—®å´å®¶å“",
            "å¥½åƒä¸å¤ªä¼šï¼Ÿ",
            "æˆ‘é‡Œä¸ªè±†é˜¿ï¼Œä½ é—®å‡ºè¿™ä¹ˆéš¾çš„é—®é¢˜æˆ‘æ€ä¹ˆä¼šå‘¢ï¼Ÿ"
        ]
        
        self.conversation_manager = conversation_manager or ConversationManager()
        
        # åˆå§‹åŒ–Qwen APIå®¢æˆ·ç«¯
        self.client = OpenAI(
            api_key="",
            base_url="")
        
        # ç³»ç»Ÿæ¶ˆæ¯è®¾ç½®
        self.sys_msg = {
            "role": "system",                                                           
            "content": "å›ç­”ç®€æ´"
        }

    def _load_vectorstore_with_retry(self, max_retries=3):
        for i in range(max_retries):
            try:
                return FAISS.load_local(self.faiss_index_path, self.embedding_model, allow_dangerous_deserialization=True)
            except Exception as e:
                logging.warning(f"ç¬¬{i+1}æ¬¡åŠ è½½ FAISS å¤±è´¥: {e}")
                time.sleep(1)
        raise RuntimeError("åŠ è½½å‘é‡å­˜å‚¨å¤±è´¥")
    
    async def ask_stream(self, question, context=True):
        start_time = time.time()
        
        context = ""
        if context:
            context = self.conversation_manager.get_conversation_context(max_context=3)
        
        docs = await asyncio.to_thread(
            self.vectorstore.as_retriever(search_kwargs={"k": self.k_documents}).invoke,
            question
        )

        if not docs:
            result = "æœªæ£€ç´¢åˆ°ç›¸å…³å†…å®¹ã€‚"
   
            response_time = time.time() - start_time
            await self.conversation_manager.add_conversation_entry(question, result, response_time)
            yield result
            return
        
        query = "ä½ æ˜¯ä¸€ä¸ªç”˜è–¯ä¸“å®¶ï¼Œè¯·ä½ ä»¥è¯´è¯çš„æ ‡å‡†å›ç­”ï¼Œè¯·ä½ æ ¹æ®å‚è€ƒå†…å®¹å›ç­”ï¼Œå›ç­”è¾“å‡ºä¸ºä¸€æ®µï¼Œå›ç­”å†…å®¹ç®€æ´ï¼Œå¦‚æœå‚è€ƒå†…å®¹ä¸­æ²¡æœ‰ä»»ä½•ç›¸å…³ä¿¡æ¯ï¼Œè¯·å›ç­”'{}'ã€‚".format(random.choice(self.unknown_responses))
        
        # æ„å»ºåŒ…å«ä¸Šä¸‹æ–‡çš„æç¤º
        doc_context = "\n\n".join([d.page_content for d in docs])
        
        # å¦‚æœæœ‰å¯¹è¯å†å²ï¼Œå°†å…¶åŠ å…¥æç¤º
        if context:
            prompt = f"å¯¹è¯å†å²:\n{context}\n\nå‚è€ƒå†…å®¹:\n{doc_context}\n\nå½“å‰é—®é¢˜:\n{question}\n\n"#è¦æ±‚:{query}\n\n"
        else:
            prompt = f"å‚è€ƒå†…å®¹:\n{doc_context}\n\né—®é¢˜:\n{question}\n\n"#è¦æ±‚:{query}\n\n"
        
        # ä½¿ç”¨Qwen APIè¿›è¡Œæµå¼è°ƒç”¨
        messages = [
            self.sys_msg,
            {"role": "user", "content": prompt}
        ]
        
        try:
            stream = self.client.chat.completions.create(
                model="qwen2.5-omni-7b",  
                messages=messages,
                temperature=self.temperature,
                max_tokens=400,
                stream=True
            )
            
            full_response = ""
            for chunk in stream:
                if chunk.choices:
                    content = chunk.choices[0].delta.content or ""
                    full_response += content
                    yield content
            
            response_time = time.time() - start_time
            await self.conversation_manager.add_conversation_entry(question, full_response, response_time)
            await self.conversation_manager.save_tracking_data()
                    
        except Exception as e:
            error_msg = f"APIè°ƒç”¨å‡ºé”™: {e}"
            logging.error(f"APIè°ƒç”¨å¤±è´¥: {e}")
            await self.conversation_manager.record_error("API_ERROR", str(e))
            yield error_msg

# ==================================
# UI ç»„ä»¶ç±»
# ==================================
class MessageBubble(QWidget):
    """ä¼˜åŒ–çš„èŠå¤©æ°”æ³¡ç»„ä»¶"""
    def __init__(self, text, is_user=False, parent=None):
        super().__init__(parent)
        self.text = text
        self.is_user = is_user
        self._msg_label = None

        # å¤´åƒè·¯å¾„
        self.avatar_path = "guzz.png"
        self.robot_path = "sweetpotato.jpg"

        # ä¸º7å¯¸å±å¹•ä¼˜åŒ–å¸ƒå±€
        layout = QHBoxLayout(self)
        layout.setContentsMargins(0, 12, 0, 12)  
        layout.setSpacing(15)

        avatar_size = 60
        avatar_label = QLabel()
        avatar_label.setFixedSize(avatar_size, avatar_size)
        avatar_label.setAlignment(Qt.AlignCenter)
        avatar_label.setStyleSheet(f"""
            border-radius: 5px;
            background-color: #DDDDDD;
            border: 3px solid {"#4CAF50" if is_user else "#FF9800"};
        """)

        # åŠ è½½å¤´åƒå›¾åƒ
        avatar_path = self.avatar_path if is_user else self.robot_path
        pixmap = QPixmap(avatar_path)

        scaled = pixmap.scaled(
            avatar_size, avatar_size,
            Qt.KeepAspectRatioByExpanding,
            Qt.SmoothTransformation
        )
        avatar_label.setPixmap(scaled)

        self._msg_label = QLabel(text)
        self._msg_label.setFont(QFont("å¾®è½¯é›…é»‘", 16))  # å¢å¤§å­—ä½“
        self._msg_label.setWordWrap(True)
        self._msg_label.setMaximumWidth(780)  # å¢åŠ æœ€å¤§å®½åº¦
        self._msg_label.setStyleSheet(f"""
            background-color: {"#A4E75A" if is_user else "#FFFFFF"};
            color: #303030;
            border-radius: 20px;
            padding: 15px 20px;
            border: 2px solid {"#8BC34A" if is_user else "#E0E0E0"};
        """)

        # æŒ‰æ¶ˆæ¯æ¥æºè®¾ç½®å·¦å³å¸ƒå±€
        if is_user:
            layout.addStretch()
            layout.addWidget(self._msg_label)
            layout.addWidget(avatar_label)
        else:
            layout.addWidget(avatar_label)
            layout.addWidget(self._msg_label)
            layout.addStretch()

        self.setMinimumHeight(80)

    @property
    def msg_label(self):
        return self._msg_label

    def update_text(self, text):
        if self._msg_label:
            self._msg_label.setText(text)


class ChatArea(QScrollArea):
    """ä¼˜åŒ–çš„èŠå¤©åŒºåŸŸ"""
    def __init__(self, parent=None):
        super().__init__(parent)
        
        # è®¾ç½®æ»šåŠ¨åŒºåŸŸå±æ€§
        self.setWidgetResizable(True)
        self.setFrameShape(QFrame.NoFrame)
        self.setVerticalScrollBarPolicy(Qt.ScrollBarAsNeeded)
        self.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        
        # ç¾åŒ–æ»šåŠ¨æ¡æ ·å¼
        self.setStyleSheet("""
            QScrollArea {
                background-color: #F5F5F5;
                border: none;
            }
            QScrollBar:vertical {
                border: none;
                background: rgba(0, 0, 0, 0.05);
                width: 10px;
                margin: 0px;
                border-radius: 5px;
            }
            QScrollBar::handle:vertical {
                background: rgba(0, 0, 0, 0.15);
                min-height: 30px;
                border-radius: 5px;
            }
            QScrollBar::handle:vertical:hover {
                background: rgba(0, 0, 0, 0.25);
            }
            QScrollBar::add-line:vertical, QScrollBar::sub-line:vertical {
                height: 0px;
            }
        """)
        
        # åˆ›å»ºå®¹å™¨å°éƒ¨ä»¶
        self.container = QWidget()
        self.container.setStyleSheet("background-color: #F5F5F5;")
        
        # åˆ›å»ºå‚ç›´å¸ƒå±€
        self.layout = QVBoxLayout(self.container)
        self.layout.setAlignment(Qt.AlignTop)
        self.layout.setSpacing(20)  # å¢åŠ é—´è·ä½¿ç•Œé¢æ›´æ¸…çˆ½
        self.layout.setContentsMargins(20, 20, 20, 20)
        
        # è®¾ç½®æ»šåŠ¨åŒºåŸŸçš„å°éƒ¨ä»¶
        self.setWidget(self.container)
    

    def smooth_scroll_to_bottom(self):
        """æ›´å¹³æ»‘åœ°æ»šåŠ¨åˆ°åº•éƒ¨"""
        scrollbar = self.verticalScrollBar()
        current = scrollbar.value()
        maximum = scrollbar.maximum()
        
        # å¦‚æœå·²ç»æ¥è¿‘åº•éƒ¨ï¼Œç›´æ¥è·³åˆ°åº•éƒ¨
        if maximum - current < 100:
            scrollbar.setValue(maximum)
            return
            
        # å¦åˆ™ä½¿ç”¨åŠ¨ç”»æ•ˆæœ
        steps = 5
        step_size = (maximum - current) / steps
        
        for i in range(steps):
            def scroll_step(idx=i):
                new_val = min(current + (idx + 1) * step_size, maximum)
                scrollbar.setValue(int(new_val))
            
            QTimer.singleShot(30 * (i + 1), scroll_step)
    
    def add_message(self, text, is_user=False):
        """æ·»åŠ æ–°æ¶ˆæ¯"""
        if not text and not is_user:  # å…è®¸æœºå™¨äººæ·»åŠ ç©ºæ¶ˆæ¯ï¼ˆä½œä¸ºå ä½ç¬¦ï¼‰
           bubble = MessageBubble("", is_user, self)
           self.layout.addWidget(bubble)
           QTimer.singleShot(100, lambda: self.scrollToBottom())
           return bubble
        elif not text:  # ç”¨æˆ·æ¶ˆæ¯ä¸èƒ½ä¸ºç©º
           return None
           
       # åˆ›å»ºæ°”æ³¡æ¶ˆæ¯
        bubble = MessageBubble(text, is_user, self)
        self.layout.addWidget(bubble)
        
        # ä½¿ç”¨Timerç¡®ä¿æ»šåŠ¨åœ¨æ¸²æŸ“åæ‰§è¡Œ
        QTimer.singleShot(100, lambda: self.scrollToBottom())
        return bubble
    
    def scrollToBottom(self):
        """æ»šåŠ¨åˆ°åº•éƒ¨"""
        self.verticalScrollBar().setValue(self.verticalScrollBar().maximum())
    
    def update_bubble_widths(self, width):
        """æ›´æ–°æ‰€æœ‰æ°”æ³¡çš„å®½åº¦"""
        max_width = min(800, int(width * 0.7))  
        for i in range(self.layout.count()):
            item = self.layout.itemAt(i)
            if item and item.widget():
                bubble = item.widget()
                if hasattr(bubble, 'msg_label'):
                    bubble.msg_label.setMaximumWidth(max_width)

class StatusIndicator(QWidget):
    """è¯­éŸ³çŠ¶æ€æŒ‡ç¤ºå™¨"""
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setFixedHeight(50)
        self.setStyleSheet("""
            QWidget {
                background-color: #FFFFFF;
                border-bottom: 2px solid #E0E0E0;
            }
        """)
        
        self.layout = QHBoxLayout(self)
        self.layout.setContentsMargins(20, 10, 20, 10)
        
        # çŠ¶æ€å›¾æ ‡
        self.icon_label = QLabel()
        self.icon_label.setFixedSize(24, 24)
        self.icon_label.setStyleSheet("""
            background-color: #5B89DB; 
            border-radius: 12px;
            border: 2px solid white;
        """)
        
        # çŠ¶æ€æ–‡æœ¬
        self.text_label = QLabel("æ­£åœ¨åˆå§‹åŒ–...")
        self.text_label.setFont(QFont("å¾®è½¯é›…é»‘", 14, QFont.Bold))
        self.text_label.setStyleSheet("color: #333333;")
        
        self.layout.addWidget(self.icon_label)
        self.layout.addWidget(self.text_label)
        self.layout.addStretch()
        
        # åˆå§‹çŠ¶æ€
        self.set_waiting()
        
    def set_waiting(self):
        """è®¾ç½®ç­‰å¾…çŠ¶æ€"""
        self.text_label.setText("ç­‰å¾…è¯­éŸ³è¾“å…¥...")
        self.icon_label.setStyleSheet("""
            background-color: #5B89DB; 
            border-radius: 12px;
            border: 2px solid white;
        """)
        
    def set_listening(self):
        """è®¾ç½®ç›‘å¬çŠ¶æ€"""
        self.text_label.setText("æ­£åœ¨è†å¬...")
        self.icon_label.setStyleSheet("""
            background-color: #F44336; 
            border-radius: 12px;
            border: 2px solid white;
        """)
        
    def set_processing(self):
        """è®¾ç½®å¤„ç†çŠ¶æ€"""
        self.text_label.setText("æ­£åœ¨æ€è€ƒ...")
        self.icon_label.setStyleSheet("""
            background-color: #FFC107; 
            border-radius: 12px;
            border: 2px solid white;
        """)
        
    def set_answering(self):
        '''è®¾ç½®å›ç­”çŠ¶æ€'''
        self.text_label.setText("æ­£åœ¨æ’­æ”¾æ¬¢è¿è¯­...")
        self.icon_label.setStyleSheet("""
            background-color: #E91E63; 
            border-radius: 12px;
            border: 2px solid white;
        """)
        
    def set_answerd(self):
        """è®¾ç½®å›ç­”çŠ¶æ€"""
        self.text_label.setText("æ­£åœ¨å›ç­”ä¸­...")
        self.icon_label.setStyleSheet("""
            background-color: #4CAF50; 
            border-radius: 12px;
            border: 2px solid white;
        """)

# ==================================
# ä¸»åº”ç”¨ç±»
# ==================================
class SignalBridge(QObject):
    """ä¿¡å·æ¡¥æ¥ç±»ï¼Œç”¨äºå¼‚æ­¥é€šä¿¡"""
    status_changed = Signal(str)
    add_user_message = Signal(str)
    start_bot_message = Signal()
    update_bot_message = Signal(str)
    request_real_time_listening = Signal()


class SweetPotatoGUI(QMainWindow):
    def __init__(self, user_name="å´å¤§ç‹"):
        super().__init__()
        self.user_name = user_name
        self.current_bot_bubble = None
        
        self.follow_up_prompts = [
    "æ‚¨è¿˜æœ‰ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ",
    "æ‚¨è¿˜æœ‰ä»€ä¹ˆæƒ³é—®çš„ï¼Ÿ",
    "æ‚¨è¿˜æƒ³äº†è§£äº›ä»€ä¹ˆï¼Ÿ",
    "è¿˜æœ‰å…¶ä»–å…³äºç”˜è–¯çš„é—®é¢˜å—ï¼Ÿ",
    "æƒ³æˆä¸ºå´å®¶å“å—ï¼Ÿ",
    "è¿˜æœ‰ä»€ä¹ˆç–‘é—®å‘¢",
    "å˜¿å˜¿å˜¿ä½ è¯´å‘€ï¼Ÿ",
    "å¤ªè±†äº†ä½ ï¼Œèµ¶ç´§è¯´ï¼Ÿ"
]
   
        



        # åˆå§‹åŒ–ç»„ä»¶
        self.chat_area = ChatArea()
        self.status_indicator = StatusIndicator()

        # ä¿¡å·æ¡¥æ¥
        self.bridge = SignalBridge()
        self.bridge.status_changed.connect(self.update_status)
        self.bridge.add_user_message.connect(self.add_question)
        self.bridge.start_bot_message.connect(self.start_bot_message)
        self.bridge.update_bot_message.connect(self.update_bot_message)
        self.bridge.request_real_time_listening.connect(self.start_real_time_listening)

        # è¾…åŠ©
        self.conversation_manager = ConversationManager(max_history=10)
        self.qa_model = KnowledgeQA(conversation_manager=self.conversation_manager)
        self.asr_helper = ASRHelper()
        self.tts_streamer = TTSStreamer()

        # å¼‚æ­¥å±æ€§
        self.current_tasks = []
        self.current_answer = ""
        self.is_processing = False

        # UI ä¸äº‹ä»¶å¾ªç¯
        self.init_ui()
        self.setup_asyncio_event_loop()
        # æ’­æ”¾æ¬¢è¿å¹¶å¼€å§‹æµç¨‹
        self.add_task(self.play_welcome_and_listen())

    def init_ui(self):
        self.setWindowTitle("ç”˜è–¯çŸ¥è¯†é—®ç­”ç³»ç»Ÿ")
        self.showFullScreen()
        
        # è®¾ç½®çª—å£èƒŒæ™¯
        self.setStyleSheet("""
            QMainWindow {
                background-color: #FAFAFA;
            }
        """)
        
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        main_layout = QVBoxLayout(central_widget)
        main_layout.setSpacing(0)
        main_layout.setContentsMargins(0, 0, 0, 0)

        # Header åŒºåŸŸ - æ›´ç¾è§‚çš„è®¾è®¡
        header = QWidget()
        header.setStyleSheet("""
            QWidget {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:0,
                    stop:0 #FF9800, stop:1 #FFA726);
                border-bottom: 3px solid #F57C00;
            }
        """)
        header.setFixedHeight(70)
        header_layout = QHBoxLayout(header)
        header_layout.setContentsMargins(20, 10, 20, 10)

        # Logo åŒºåŸŸ
        logo_container = QWidget()
        logo_container.setFixedSize(50, 50)
        logo_container.setStyleSheet("""
            background-color: white;
            border-radius: 25px;
            border: 3px solid #FFB74D;
        """)
        # logo_label = QLabel("ğŸ ")
        # logo_label.setAlignment(Qt.AlignCenter)
        # logo_label.setFont(QFont("å¾®è½¯é›…é»‘", 24))
        # logo_label.setStyleSheet("background-color: transparent; border: none;")
        # logo_layout = QHBoxLayout(logo_container)
        # logo_layout.setContentsMargins(0, 0, 0, 0)
        # logo_layout.addWidget(logo_label)

        # æ ‡é¢˜
        title_label = QLabel("ç”˜è–¯çŸ¥è¯†åŠ©æ‰‹")
        title_label.setFont(QFont("å¾®è½¯é›…é»‘", 22, QFont.Bold))
        title_label.setAlignment(Qt.AlignVCenter)
        title_label.setStyleSheet("""
            color: white;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
            background-color: transparent;
            border: none;
        """)

        # ç”¨æˆ·ä¿¡æ¯
        user_container = QWidget()
        user_container.setStyleSheet("""
            background-color: rgba(255, 255, 255, 0.2);
            border-radius: 20px;
            padding: 5px 15px;
        """)
        user_label = QLabel(f"{self.user_name}")
        user_label.setFont(QFont("å¾®è½¯é›…é»‘", 16, QFont.Bold))
        user_label.setAlignment(Qt.AlignRight | Qt.AlignVCenter)
        user_label.setStyleSheet("""
            color: white;
            background-color: transparent;
            border: none;
        """)
        user_layout = QHBoxLayout(user_container)
        user_layout.setContentsMargins(10, 5, 10, 5)
        user_layout.addWidget(user_label)

        header_layout.addWidget(logo_container)
        header_layout.addWidget(title_label)
        header_layout.addStretch(1)
        header_layout.addWidget(user_container)

        main_layout.addWidget(header)
        main_layout.addWidget(self.status_indicator)
        main_layout.addWidget(self.chat_area, 1)

        # ESC é€€å‡º
        self.exit_shortcut = QShortcut(QKeySequence("Esc"), self)
        self.exit_shortcut.activated.connect(self.close)

    def setup_asyncio_event_loop(self):
        self.loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self.loop)
        self.timer = QTimer(self)
        self.timer.timeout.connect(self._process_asyncio_events)
        self.timer.start(10)

    def _process_asyncio_events(self):
        self.loop.call_soon(lambda: None)
        self.loop.stop()
        self.loop.run_forever()

    def add_task(self, coro):
        task = self.loop.create_task(coro)
        self.current_tasks.append(task)
        task.add_done_callback(lambda t: self.current_tasks.remove(t) if t in self.current_tasks else None)
        return task

    async def play_welcome_and_listen(self):
        welcome_msg = f"æ‚¨å¥½ï¼Œ{self.user_name}ï¼æˆ‘æ˜¯ç”˜è–¯çŸ¥è¯†åŠ©æ‰‹ï¼Œè¯·é€šè¿‡è¯­éŸ³å‘æˆ‘æé—®å…³äºç”˜è–¯çš„é—®é¢˜ã€‚"
        # æ˜¾ç¤ºæ–‡å­—
        self.chat_area.add_message(welcome_msg)
        # åˆ‡åˆ°"å›ç­”ä¸­"çŠ¶æ€
        self.status_indicator.set_answering()
        # æ’­æŠ¥å¹¶ç­‰å¾…å®Œæˆ
        await self.tts_streamer.speak_text(welcome_msg, wait=True)
        
        # è¯­éŸ³æç¤ºï¼ˆä¸æ˜¾ç¤ºåœ¨å±å¹•ä¸Šï¼‰
        await self.tts_streamer.speak_text("æ‚¨æœ‰ä»€ä¹ˆæƒ³é—®çš„å—ï¼Ÿ", wait=True)
        
        # è®¾ç½®ä¸º"å·²å›ç­”"çŠ¶æ€
        self.status_indicator.set_answerd()
        # åˆ‡åˆ°"è†å¬"çŠ¶æ€å¹¶å¯åŠ¨è¿ç»­è†å¬
        self.status_indicator.set_listening()
        await asyncio.sleep(0.2)
        self.add_task(self.continuous_listening_task())

    async def continuous_listening_task(self):
        while True:
            try:
                # ä¿è¯ TTS å®Œæ¯•
                if self.tts_streamer.is_speaking:
                    await self.tts_streamer.wait_until_done()
                    await asyncio.sleep(0.1)
                await self.clear_audio_buffer()

                # è¯­éŸ³è¯†åˆ«
                text = await self.asr_helper.real_time_recognition(
                    callback=lambda status: self.bridge.status_changed.emit(status)
                )

                if text and not self.is_processing:
                    self.is_processing = True
                    # æ–°é—®é¢˜ï¼Œåˆ‡åˆ°"å¤„ç†"çŠ¶æ€
                    self.bridge.add_user_message.emit(text)
                    self.status_indicator.set_processing()

                    # å¼€å§‹æœºå™¨äººæ¶ˆæ¯
                    self.bridge.start_bot_message.emit()
                    self.current_answer = ""
                    
                    # æ–‡æœ¬ç¼“å†²åŒº
                    text_buffer = ""
                    # è®¡ç®—ç¼“å†²åŒºä¸­æ ‡ç‚¹ç¬¦å·çš„æ•°é‡
                    punctuation_count = 0
                    # è®¾ç½®æ ‡ç‚¹ç¬¦å·é˜ˆå€¼ï¼Œè¾¾åˆ°è¿™ä¸ªæ•°é‡æ‰å‘é€
                    punctuation_threshold = 3  # å¯ä»¥è°ƒæ•´ä¸º3æˆ–4
                    
                    # è®¾ç½®ä¸ºå›ç­”çŠ¶æ€
                    self.status_indicator.set_answerd()

                    # æµå¼ç”Ÿæˆå›ç­”å¹¶åŒæ­¥è¿›è¡Œè¯­éŸ³åˆæˆ
                    async for chunk in self.qa_model.ask_stream(text):
                        self.current_answer += chunk
                        self.bridge.update_bot_message.emit(self.current_answer)
                        
                        # å°†æ–°å—æ·»åŠ åˆ°ç¼“å†²åŒº
                        text_buffer += chunk
                        
                        # è®¡ç®—å½“å‰å—ä¸­çš„æ ‡ç‚¹ç¬¦å·æ•°é‡
                        new_punctuations = len(re.findall(r'[ã€‚ï¼Œ,.!?ï¼ï¼Ÿ;ï¼›]', chunk))
                        punctuation_count += new_punctuations
                        
                        # æ¡ä»¶ï¼šè¾¾åˆ°æ ‡ç‚¹ç¬¦å·é˜ˆå€¼æˆ–ç¼“å†²åŒºè¶³å¤Ÿé•¿
                        if (punctuation_count >= punctuation_threshold and len(text_buffer) >= 15) or len(text_buffer) > 80:
                            if text_buffer.strip():
                                await self.tts_streamer.speak_text(text_buffer, wait=False)
                            
                            # é‡ç½®ç¼“å†²åŒºå’Œè®¡æ•°å™¨
                            text_buffer = ""
                            punctuation_count = 0
                        
                        # ç»™UIæ¸²æŸ“çš„æ—¶é—´
                        await asyncio.sleep(0.01)
                    
                    # å¤„ç†å‰©ä½™çš„æ–‡æœ¬ç¼“å†²åŒº
                    if text_buffer.strip():
                        await self.tts_streamer.speak_text(text_buffer, wait=False)
                    
                    # ç­‰å¾…æ‰€æœ‰è¯­éŸ³æ’­æ”¾å®Œæˆ
                    await self.tts_streamer.wait_until_done()
                    
                    # è¯­éŸ³æç¤ºç»§ç»­å¯¹è¯ï¼ˆä¸æ˜¾ç¤ºåœ¨å±å¹•ä¸Šï¼‰
                    follow_up = random.choice(self.follow_up_prompts)
                    await self.tts_streamer.speak_text(follow_up, wait=True)
                    
                    # æ’­æŠ¥ç»“æŸï¼Œåˆ‡åˆ°"è†å¬"
                    self.status_indicator.set_listening()
                    self.is_processing = False

                await asyncio.sleep(0.5)
            except Exception as e:
                logging.error(f"è¿ç»­è†å¬è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                self.is_processing = False
                await asyncio.sleep(1)

    async def clear_audio_buffer(self):
        try:
            if hasattr(self.asr_helper, 'stream') and self.asr_helper.stream:
                await asyncio.sleep(0.1)
                while self.asr_helper.stream.get_read_available() > 0:
                    self.asr_helper.stream.read(self.asr_helper.CHUNK, exception_on_overflow=False)
                logging.info("éŸ³é¢‘ç¼“å†²åŒºå·²æ¸…ç†")
        except Exception as e:
            logging.warning(f"æ¸…ç†éŸ³é¢‘ç¼“å†²åŒºæ—¶å‡ºé”™: {e}")

    def update_status(self, status):
        if status == "waiting":
            self.status_indicator.set_waiting()
        elif status == "listening":
            self.status_indicator.set_listening()
        elif status == "processing":
            self.status_indicator.set_processing()
        elif status == "answering":
            self.status_indicator.set_answerd()

    def add_question(self, text):
        self.chat_area.add_message(text, is_user=True)
        self.status_indicator.set_processing()

    def start_bot_message(self):
        self.current_bot_bubble = self.chat_area.add_message("", is_user=False)
        # åœ¨ start_bot_message ä¸­åŠ åŠ¨ç”»æ§åˆ¶
        self.loading_dots_timer = QTimer()
        self.loading_dots = ""
        self.loading_dots_timer.timeout.connect(self.animate_loading_dots)
        self.loading_dots_timer.start(500)  # æ¯ 500ms æ›´æ–°ä¸€æ¬¡

    def animate_loading_dots(self):
        self.loading_dots = "." * ((len(self.loading_dots) % 3) + 1)
        if self.current_bot_bubble:
            self.current_bot_bubble.update_text(f"æ­£åœ¨æ€è€ƒä¸­{self.loading_dots}")
    def update_bot_message(self, text):
        """æ›´æ–°æœºå™¨äººæ¶ˆæ¯"""
        if self.loading_dots_timer.isActive():
            self.loading_dots_timer.stop()
        if self.current_bot_bubble:
            self.current_bot_bubble.update_text(text)
            
            # ä½¿ç”¨æ”¹è¿›çš„å¹³æ»‘æ»šåŠ¨
            QTimer.singleShot(10, lambda: self.chat_area.smooth_scroll_to_bottom())

    def start_real_time_listening(self):
        if self.is_processing:
            return
        self.status_indicator.set_listening()
        self.add_task(self.continuous_listening_task())

    def stop_recording(self):
        self.asr_helper.stop_recording()

    def resizeEvent(self, event):
        super().resizeEvent(event)
        if hasattr(self, 'chat_area') and self.chat_area:
            self.chat_area.update_bubble_widths(self.width())

    def closeEvent(self, event):
        for task in self.current_tasks:
            task.cancel()
        self.asr_helper.close_audio()
        self.timer.stop()
        loop = asyncio.get_event_loop()
        loop.run_until_complete(self.conversation_manager.save_tracking_data())
        super().closeEvent(event)

if __name__ == "__main__":
    app = QApplication(sys.argv)
    
    # è®¾ç½®å…¨å±€æ ·å¼
    app.setStyle("Fusion")
    
    window = SweetPotatoGUI("å´å®¶å“")
    window.show()
    
    sys.exit(app.exec_())