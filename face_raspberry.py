import sys
import os
sys.path.append(os.path.abspath("/home/joe/chatbox"))
import cv2
import face_recognition
import numpy as np
import time
import pickle
import subprocess
import os

class FaceRecognizer:
    def __init__(self,timeout=10,face_model="face/face_model.pkl",model_file = 'face_track/models/deploy.prototxt',weights_file = 'face_track/models/res10_300x300_ssd_iter_140000.caffemodel'):
        self.known_faces = {}
        self.known_face_names = []
        self.known_face_encodings = []
        self.process = None
        self.start_time = time.time() 
        self.frame_count = 0 
        self.recognized_user = None  # ä¿®æ­£å˜é‡åä¸è·å–æ–¹æ³•ä¸€è‡´
        self.timeout = timeout
        self.face_model = face_model
        self.model_file = model_file
        self.weights_file = weights_file
        
        self._load_known_faces()
        self.use_dnn = self._check_dnn_models()
        self._init_camera()


    def _check_dnn_models(self):
        """æ£€æŸ¥æ˜¯å¦å­˜åœ¨DNNæ¨¡å‹æ–‡ä»¶"""
        
        
        print("æ‰¾åˆ°DNNæ¨¡å‹æ–‡ä»¶ï¼Œå°è¯•åŠ è½½...")
        self.face_net = cv2.dnn.readNet(self.model_file, self.weights_file)
        print("æˆåŠŸåŠ è½½DNNæ¨¡å‹")
        return True
            
    def _load_known_faces(self):
        """åŠ è½½äººè„¸æ•°æ®åº“"""
        try:
            with open(self.face_model, "rb") as f:
                self.known_faces = pickle.load(f)
                self.known_face_names = list(self.known_faces.keys())
                self.known_face_encodings = list(self.known_faces.values())
                print("æˆåŠŸåŠ è½½äººè„¸æ•°æ®åº“ï¼")
        except FileNotFoundError:
            print("æœªæ‰¾åˆ°äººè„¸æ•°æ®åº“ï¼Œè¯·å…ˆè¿è¡Œåˆ›å»ºæ•°æ®åº“è„šæœ¬ï¼")
            exit()

    def _init_camera(self):
        """åˆå§‹åŒ–æ‘„åƒå¤´ï¼Œä½¿ç”¨libcamera-vid"""
        # ä¼˜åŒ–æ‘„åƒå¤´å‚æ•°ï¼Œé™ä½å¸§ç‡å‡è½»å¤„ç†è´Ÿæ‹…
        cmd = "libcamera-vid -t 0 --width 320 --height 240 --codec mjpeg --nopreview --framerate 15 -o -"
        try:
            self.process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE, bufsize=1024*1024)
            print("æ‘„åƒå¤´åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"åˆå§‹åŒ–æ‘„åƒå¤´å¤±è´¥: {e}")
            exit()

    def get_frame(self):
        """ä»libcamera-vidè·å–è§†é¢‘å¸§"""
        buffer = bytearray()
        try:
            while True:
                data = self.process.stdout.read(1024)
                if not data:
                    print("æ— æ³•è¯»å–è§†é¢‘æ•°æ®")
                    return False, None
                buffer.extend(data)
                start = buffer.find(b'\xff\xd8')
                end = buffer.find(b'\xff\xd9', start)
                if start != -1 and end != -1:
                    jpeg = buffer[start:end + 2]
                    buffer = buffer[end + 2:]
                    # ç›´æ¥è§£ç ä¸ºBGRæ ¼å¼ï¼Œå‡å°‘è½¬æ¢å¼€é”€
                    frame = cv2.imdecode(np.frombuffer(jpeg, dtype=np.uint8), cv2.IMREAD_COLOR)
                    if frame is None:
                        print("è§£ç å¸§å¤±è´¥")
                        continue
                    frame = cv2.flip(frame, 0)
                    # æ ¹æ®åç»­å¤„ç†éœ€è¦çš„æ ¼å¼è¿”å›
                    if self.use_dnn:
                        return True, frame  
                    else:
                        return True, cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  
                    
        except Exception as e:
            print(f"è·å–è§†é¢‘å¸§å¤±è´¥: {e}")
            return False, None

    def detect_faces_dnn(self, frame):
        """ä½¿ç”¨DNNæ¨¡å‹æ£€æµ‹äººè„¸"""
        try:
            h, w = frame.shape[:2]
            # åˆ›å»ºblobå¹¶è¿›è¡Œå‰å‘ä¼ æ’­
            blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), [104, 117, 123], False, False)
            self.face_net.setInput(blob)
            detections = self.face_net.forward()
            
            face_locations = []
            
            # æ£€æµ‹ç»“æœå¤„ç†
            for i in range(detections.shape[2]):
                confidence = detections[0, 0, i, 2]
                if confidence > 0.5:  # ç½®ä¿¡åº¦é˜ˆå€¼
                    x1 = int(detections[0, 0, i, 3] * w)
                    y1 = int(detections[0, 0, i, 4] * h)
                    x2 = int(detections[0, 0, i, 5] * w)
                    y2 = int(detections[0, 0, i, 6] * h)
                    
                    # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
                    x1, y1 = max(0, x1), max(0, y1)
                    x2, y2 = min(w, x2), min(h, y2)
                    
                    if x2 > x1 and y2 > y1:  # æœ‰æ•ˆçš„äººè„¸åŒºåŸŸ
                        face_locations.append((y1, x2, y2, x1))  # top, right, bottom, left
            
            return face_locations
        except Exception as e:
            print(f"DNNäººè„¸æ£€æµ‹å¤±è´¥: {e}")
            return []

    def recognize_faces(self, frame):
        """æ‰§è¡Œäººè„¸è¯†åˆ«"""
        try:
            # ä½¿ç”¨DNNæˆ–face_recognitionè¿›è¡Œäººè„¸æ£€æµ‹
            if self.use_dnn:
                face_locations = self.detect_faces_dnn(frame)
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            else:
                rgb_frame = frame  # face_recognitionå·²ç»ä½¿ç”¨RGBæ ¼å¼
                face_locations = face_recognition.face_locations(rgb_frame, model="hog", number_of_times_to_upsample=0)
            
            # è·³è¿‡å°äººè„¸ï¼Œå‡å°‘è®¡ç®—é‡
            valid_face_locations = []
            for loc in face_locations:
                top, right, bottom, left = loc
                face_size = (bottom - top) * (right - left)
                if face_size > 1000:  # é¢ç§¯é˜ˆå€¼
                    valid_face_locations.append(loc)
            
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆäººè„¸ï¼Œæå‰è¿”å›
            if not valid_face_locations:
                return []
            
            # å¯¹æ¯ä¸ªäººè„¸è®¡ç®—ç‰¹å¾ç¼–ç 
            start = time.time()
            face_encodings = face_recognition.face_encodings(rgb_frame, valid_face_locations, model="small")
            
            results = []
            for (top, right, bottom, left), face_encoding in zip(valid_face_locations, face_encodings):
                # åªåœ¨æ¨¡å‹åŠ è½½åæ‰è¿›è¡Œæ¯”è¾ƒ
                if self.known_face_encodings:
                    matches = face_recognition.compare_faces(
                        self.known_face_encodings, face_encoding, tolerance=0.45
                    )
                    name = "who?"
                    face_distances = face_recognition.face_distance(
                        self.known_face_encodings, face_encoding
                    )
                    if True in matches:
                        best_match_index = face_distances.argmin()
                        if face_distances[best_match_index] < 0.4:
                            name = self.known_face_names[best_match_index]
                            end = time.time()
                            elapsed = end - start
                            # print(f"è¯†åˆ«åˆ°ä½ å•¦ {name}! è€—æ—¶ {elapsed:.3f} ç§’")
                else:
                    name = "who?"
                    
                results.append(((top, right, bottom, left), name))
            
            # print(f"æ£€æµ‹åˆ° {len(results)} å¼ äººè„¸")
            return results
        except Exception as e:
            print(f"äººè„¸è¯†åˆ«å¤±è´¥: {e}")
            return []

  

    def release(self):
        """é‡Šæ”¾èµ„æº"""
        try:
            if self.process:
                self.process.terminate()
                self.process.wait(timeout=2)
                print("æ‘„åƒå¤´è¿›ç¨‹å·²ç»ˆæ­¢")
        except Exception as e:
            print(f"é‡Šæ”¾èµ„æºå¤±è´¥: {e}")
        cv2.destroyAllWindows()
        print("æ‰€æœ‰èµ„æºå·²é‡Šæ”¾")
        
    def main(self, save_path):
        """ä¸»å‡½æ•°"""
        
        print("ğŸ“¸ å¼€å§‹äººè„¸è®¤è¯...")
        start_time = time.time()
        fps_start_time = time.time()
        fps_frame_count = 0
        auth_success = False

        try:
            
            while time.time() - start_time < self.timeout:
                ret, frame = self.get_frame()
                if not ret:
                    print("æ— æ³•è·å–è§†é¢‘å¸§")
                    break

                self.frame_count += 1
                fps_frame_count += 1
                
                # æ˜¾ç¤ºFPS
                if fps_frame_count >= 30:
                    current_time = time.time()
                    elapsed = current_time - fps_start_time
                    fps = fps_frame_count / elapsed
                    print(f"å½“å‰FPS: {fps:.2f}")
                    fps_frame_count = 0
                    fps_start_time = current_time
                
                # è·³å¸§å¤„ç†ï¼Œå‡è½»CPUè´Ÿæ‹…
                if self.frame_count % 2 != 0:  # æ¯éš”ä¸€å¸§å¤„ç†ä¸€æ¬¡
                    continue
                
                # å‡†å¤‡æ˜¾ç¤ºå¸§
                if self.use_dnn:
                    display_frame = frame.copy()
                else:
                    display_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                
                # è¯†åˆ«äººè„¸
                results = self.recognize_faces(frame)
                # ç»˜åˆ¶æ‰€æœ‰äººè„¸æ¡†
                for (top, right, bottom, left), name in results:
                    if name != "who?":
                        color = (0, 255, 0)
                        self.recognized_user = name
                        auth_success = True
                        # print(f"âœ… å·²è¯†åˆ«ç”¨æˆ·: {name}")  
                    else:
                        color=(0, 0, 255)

                    cv2.rectangle(display_frame, (left, top), (right, bottom), color, 2)
                    cv2.putText(display_frame, name, (left, top-15), 
                                cv2.FONT_HERSHEY_SIMPLEX, 1, color, 3)
                
                # ä¿å­˜å½“å‰å¸§
                cv2.imwrite(save_path, display_frame)
                if auth_success:
                    print(f"âœ…äººè„¸è®¤è¯æˆåŠŸï¼Œç”¨æˆ·: {self.recognized_user}")
                    break
            if not auth_success:
                print("âŒ è®¤è¯è¶…æ—¶ï¼Œæœªèƒ½è¯†åˆ«ç”¨æˆ·")
            
        except KeyboardInterrupt:
            print("ç”¨æˆ·ä¸­æ–­ç¨‹åº")
        except Exception as e:
            print(f"ç¨‹åºå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self.release()
            cv2.destroyAllWindows()

        print("ç¨‹åºå·²ç»“æŸ")
        return auth_success,self.recognized_user


if __name__ == "__main__":

    save_path = "frame.jpg"
    recognizer = FaceRecognizer()
    recognizer.main(save_path)