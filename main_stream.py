import sys
import os
import asyncio
import logging
import signal
import argparse
import time
import itertools
import threading
import re
from qa_model_easy import KnowledgeQA
from asr import ASRhelper
from tts_stream import TTSStreamer  
from face.face_recognize import FaceRecognizer
import random   
from conversation import ConversationManager


# é…ç½®æ—¥å¿— - ç¾åŒ–æ—¥å¿—æ ¼å¼
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s â”‚ %(levelname)8s â”‚ %(message)s",
    handlers=[logging.FileHandler("chatbox.log"), logging.StreamHandler()]
)


class LoadingAnimation:
    def __init__(self, desc="åŠ è½½ä¸­"):
        self.desc = desc
        self.done = False
        self.thread = None
        
    def animate(self):
        # åŠ¨ç”»ç¬¦å·é€‰é¡¹
        spinners = [
            "â ‹â ™â ¹â ¸â ¼â ´â ¦â §â ‡â ",
            "ğŸŒ‘ğŸŒ’ğŸŒ“ğŸŒ”ğŸŒ•ğŸŒ–ğŸŒ—ğŸŒ˜",
            ["[â– â–¡â–¡â–¡â–¡â–¡â–¡]", "[â– â– â–¡â–¡â–¡â–¡â–¡]", "[â– â– â– â–¡â–¡â–¡â–¡]", "[â– â– â– â– â–¡â–¡â–¡]","[â– â– â– â– â– â–¡â–¡]", "[â– â– â– â– â– â– â–¡]","[â– â– â– â– â– â– â– ]"],
            ["(â€¢_â€¢)", "( â€¢_â€¢)>âŒâ– -â– ", "(âŒâ– _â– )"],
            ["ğŸ±  ", " ğŸ± ", "  ğŸ±", " ğŸ± "],
            ["ğŸ¶â¡ï¸", "ğŸ¶ â¡ï¸", "ğŸ¶  â¡ï¸", "ğŸ¶   â¡ï¸"] 
        ]
        spinner = spinners[2]  
        
        for char in itertools.cycle(spinner):
            if self.done:
                break
            sys.stdout.write(f"\r{char} {self.desc} ")
            sys.stdout.flush()
            time.sleep(0.3)
        # æ¸…é™¤åŠ è½½åŠ¨ç”»è¡Œ
        sys.stdout.write(f"\r{'âœ… ' + self.desc + ' å®Œæˆ!':60}\n")
        sys.stdout.flush()
        
    def start(self):
        if self.thread is None or not self.thread.is_alive():
            self.done = False
            self.thread = threading.Thread(target=self.animate)
            self.thread.start()
        
    def stop(self):
        self.done = True
        if self.thread and self.thread.is_alive():
            self.thread.join(timeout=1.0)


class AnimationManager:
    """åŠ¨ç”»ç®¡ç†å™¨ - ç¡®ä¿åŒæ—¶åªæœ‰ä¸€ä¸ªåŠ¨ç”»åœ¨è¿è¡Œ"""
    def __init__(self):
        self.current_animation = None
        self.lock = threading.Lock()
    
    def start_animation(self, desc):
        """å¯åŠ¨æ–°åŠ¨ç”»ï¼Œè‡ªåŠ¨åœæ­¢ä¹‹å‰çš„åŠ¨ç”»"""
        with self.lock:
            # åœæ­¢å½“å‰åŠ¨ç”»
            if self.current_animation:
                self.current_animation.stop()
            
            # å¯åŠ¨æ–°åŠ¨ç”»
            self.current_animation = LoadingAnimation(desc)
            self.current_animation.start()
            return self.current_animation
    
    def stop_current(self):
        """åœæ­¢å½“å‰åŠ¨ç”»"""
        with self.lock:
            if self.current_animation:
                self.current_animation.stop()
                self.current_animation = None


class SweetPotatoChatbox:
    def __init__(self, voice="zh-CN-XiaoyiNeural", debug=False):
        self.voice = voice
        self.debug = debug
        self.shutdown_event = asyncio.Event()
        self.qa = None
        self.tts = None
        self.asr = None
        self.face_auth_success = False
        self.recognized_user = None
        self.first_interaction = True 
        self.conversation_manager = ConversationManager() 
        self.current_question_start_time = None
        self.follow_up_prompts = [
            "æ‚¨è¿˜æœ‰ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ",
            "æ‚¨è¿˜æœ‰ä»€ä¹ˆæƒ³é—®çš„ï¼Ÿ",
            "æ‚¨è¿˜æƒ³äº†è§£äº›ä»€ä¹ˆï¼Ÿ",
            "è¿˜æœ‰å…¶ä»–å…³äºåº·å…»å’Œè†³é£Ÿçš„é—®é¢˜å—ï¼Ÿ",
            "æƒ³å˜å¾—æ›´åŠ å¥åº·å—ï¼Ÿ",
            "è¿˜æœ‰ä»€ä¹ˆç–‘é—®å‘¢",
            "å˜¿å˜¿å˜¿ä½ è¯´å‘€ï¼Ÿ",

        ]
        self.mcp_connected = False
        
        # éŸ³ä¹äº¤äº’çŠ¶æ€ç®¡ç†
        self.music_interaction_mode = "normal"  # normal, waiting, real_time
        self.music_timer_task = None
        
        # åŠ¨ç”»ç®¡ç†å™¨
        self.animation_manager = AnimationManager()
        
        # æµå¼è¾“å‡ºç›¸å…³å±æ€§
        self.current_answer = ""
        
    async def authenticate_user(self):
        """ä½¿ç”¨äººè„¸è¯†åˆ«è¿›è¡Œç”¨æˆ·è®¤è¯"""
        logging.info("ğŸ” å¼€å§‹äººè„¸è®¤è¯...")
        print("\nğŸ“· å¼€å§‹äººè„¸è®¤è¯ï¼Œè¯·é¢å‘æ‘„åƒå¤´...")
        
        # åˆå§‹åŒ–TTSç”¨äºæç¤ºä¿¡æ¯
        temp_tts = TTSStreamer(voice=self.voice)
        await temp_tts.speak_text("å¼€å§‹äººè„¸è®¤è¯ï¼Œè¯·é¢å‘æ‘„åƒå¤´", wait=True)
        time.sleep(0.5)
        
        await asyncio.sleep(1.0)
        
        # åˆå§‹åŒ–äººè„¸è¯†åˆ«ç³»ç»Ÿ
        face_system = FaceRecognizer()
    
        # æ‰§è¡Œäººè„¸è®¤è¯
        auth_success, user_name = face_system.main("frame.jpg")
        
        # æ ¹æ®è®¤è¯ç»“æœæä¾›è¯­éŸ³åé¦ˆ
        if auth_success:
            self.conversation_manager.tracking_data['user_id'] = user_name
            welcome_message = f"æ¬¢è¿ä½ {user_name}å·²è¿›å…¥ä¸­åŒ»åº·å…»å’Œè†³é£ŸçŸ¥è¯†ç³»ç»Ÿã€‚"
            logging.info(f"âœ… è®¤è¯æˆåŠŸ: {user_name}")
            print(f"\nâœ… è®¤è¯æˆåŠŸï¼æ¬¢è¿ {user_name}")
            await temp_tts.speak_text(welcome_message, wait=True)
        else:
            deny_message = "ä½ æ˜¯è°æˆ‘ä¸è®¤è¯†ä½ ç³»ç»Ÿå°†é€€å‡ºã€‚"
            logging.info("ğŸš« è®¤è¯å¤±è´¥ï¼Œæ‹’ç»è®¿é—®")
            print("\nğŸš« è®¤è¯å¤±è´¥ï¼Œæ— æ³•è¯†åˆ«ç”¨æˆ·ï¼Œç³»ç»Ÿå°†é€€å‡º")
            await temp_tts.speak_text(deny_message, wait=True)
        
        await temp_tts.shutdown()
        return auth_success, user_name
        
    async def initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        try:
            logging.info("ğŸš€ æ­£åœ¨åˆå§‹åŒ–ä¸­åŒ»åº·å…»å’Œè†³é£Ÿé—®ç­”ç³»ç»Ÿ...")
            print("\nğŸš€ æ­£åœ¨åˆå§‹åŒ–ä¸­åŒ»åº·å…»å’Œè†³é£Ÿé—®ç­”ç³»ç»Ÿ...")
            
            # åˆå§‹åŒ–TTS
            self.animation_manager.start_animation("åˆå§‹åŒ–è¯­éŸ³åˆæˆç³»ç»Ÿ")
            self.tts = TTSStreamer(voice=self.voice)
            self.animation_manager.stop_current()
            
            try:
                await self.tts.speak_text("æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿ...", wait=True)
            except Exception as e:
                logging.error(f"âš ï¸ TTSåˆå§‹åŒ–æµ‹è¯•å¤±è´¥: {e}")
                print("âš ï¸ è­¦å‘Š: è¯­éŸ³åˆæˆæœåŠ¡ä¸å¯ç”¨ï¼Œå°†ä»¥æ–‡æœ¬æ–¹å¼æä¾›åé¦ˆ")
            
            await asyncio.sleep(0.5)
                
            # åˆå§‹åŒ–ASR
            logging.info("ğŸ¤ åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«...")
            self.animation_manager.start_animation("åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ")
            self.asr = ASRhelper()
            self.animation_manager.stop_current()
            
            # åˆå§‹åŒ–QAæ¨¡å‹
            logging.info("ğŸ§  æ­£åœ¨åŠ è½½çŸ¥è¯†æ¨¡å‹ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...")
            try:
                await self.tts.speak_text("æ­£åœ¨åŠ è½½çŸ¥è¯†æ¨¡å‹ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...", wait=True)
            except Exception as e:
                logging.error(f"âš ï¸ TTSè¯­éŸ³æ’­æ”¾å¤±è´¥: {e}")
                print("ğŸ§  æ­£åœ¨åŠ è½½çŸ¥è¯†æ¨¡å‹ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...")
            
            await asyncio.sleep(0.5)
            
            # æ˜¾ç¤ºåŠ è½½åŠ¨ç”»
            self.animation_manager.start_animation("åŠ è½½çŸ¥è¯†æ¨¡å‹")
            self.qa = KnowledgeQA(conversation_manager=self.conversation_manager)
            self.animation_manager.stop_current()

            # MCPåˆå§‹åŒ–
            self.animation_manager.start_animation("åˆå§‹åŒ–MCPæœåŠ¡")
           
            self.animation_manager.stop_current()
            
            if self.mcp_connected:
                logging.info("âœ… MCPæœåŠ¡å·²æˆåŠŸè¿æ¥")
                print("âœ… MCPæœåŠ¡å·²æˆåŠŸè¿æ¥")
            else:
                logging.warning("âš ï¸ MCPæœåŠ¡è¿æ¥å¤±è´¥ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
                print("âš ï¸ MCPæœåŠ¡è¿æ¥å¤±è´¥ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
            
            logging.info("âœ¨ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            print("\nâœ¨ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œä½ æ˜¯ä¸€ä¸ªä¸­åŒ»åº·å…»å’Œè†³é£Ÿä¸“å®¶çŸ¥è¯†åŠ©æ‰‹å·²å‡†å¤‡å°±ç»ª")
            return True
            
        except Exception as e:
            self.animation_manager.stop_current()
            logging.error(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            print(f"\nâŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
            
    def setup_signal_handlers(self):
        """è®¾ç½®ä¿¡å·å¤„ç†å™¨ç”¨äºä¼˜é›…é€€å‡º"""
        loop = asyncio.get_running_loop()
        for signame in ('SIGINT', 'SIGTERM'):
            loop.add_signal_handler(
                getattr(signal, signame),
                self.signal_handler
            )
    
    def signal_handler(self):
        """å¤„ç†ç³»ç»Ÿä¿¡å·"""
        logging.info("ğŸ›‘ æ”¶åˆ°ç³»ç»Ÿé€€å‡ºä¿¡å·ï¼Œæ­£åœ¨å®‰å…¨é€€å‡º...")
        print(f"\n{'ğŸ›‘ æ”¶åˆ°ç³»ç»Ÿé€€å‡ºä¿¡å·ï¼Œæ­£åœ¨å®‰å…¨é€€å‡º... ğŸ›‘':^80}")
        self.shutdown_event.set()
    
    async def clear_audio_buffer(self):
        """æ¸…ç†éŸ³é¢‘ç¼“å†²åŒº"""
        try:
            if hasattr(self.asr, 'stream'):
                time.sleep(0.1)
                while self.asr.stream.get_read_available() > 0:
                    self.asr.stream.read(self.asr.CHUNK, exception_on_overflow=False)
                logging.info("ğŸ§¹ éŸ³é¢‘ç¼“å†²åŒºå·²æ¸…ç†")
        except Exception as e:
            logging.warning(f"âš ï¸ æ¸…ç†éŸ³é¢‘ç¼“å†²åŒºæ—¶å‡ºé”™: {e}")

    # async def get_music_preference(self,result):
    #     """è¯¢é—®ç”¨æˆ·å¯¹éŸ³ä¹æ’­æ”¾çš„åå¥½è®¾ç½®"""
    #     logging.info("ğŸµ è¯¢é—®ç”¨æˆ·éŸ³ä¹æ’­æ”¾åå¥½")
        
    #     # è¯¢é—®ç”¨æˆ·åå¥½
    #     preference_prompt = f"{result}æ‚¨å¸Œæœ›ç­‰å¾…æ’­æ”¾å®Œæˆå†é—®é—®é¢˜ï¼Œè¿˜æ˜¯é©¬ä¸Šç»§ç»­å¯¹è¯ï¼Ÿ"
        
    #     try:
    #         await self.tts.speak_text(preference_prompt, wait=True)
    #     except Exception as e:
    #         logging.error(f"âš ï¸ æ’­æ”¾åå¥½è¯¢é—®å¤±è´¥: {e}")
    #         print("ğŸµ éŸ³ä¹å·²å¼€å§‹æ’­æ”¾ï¼Œæ‚¨å¸Œæœ›ç­‰å¾…æ’­æ”¾å®Œæˆå†é—®é—®é¢˜ï¼Œè¿˜æ˜¯é©¬ä¸Šç»§ç»­å¯¹è¯ï¼Ÿ")
        
    #     await asyncio.sleep(0.5)
    #     await self.clear_audio_buffer()
        
    #     # æ˜¾ç¤ºç›‘å¬æŒ‡ç¤ºå™¨
    #     self.animation_manager.start_animation("æ­£åœ¨è†å¬æ‚¨çš„é€‰æ‹©")
        
    #     # è·å–ç”¨æˆ·å›ç­”
    #     preference_result = self.asr.real_time_recognition()
    #     self.animation_manager.stop_current()
        
    #     if not preference_result or 'result' not in preference_result or not preference_result['result']:
    #         logging.info("âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆå›ç­”ï¼Œé»˜è®¤é€‰æ‹©é©¬ä¸Šç»§ç»­")
    #         return "immediate"
        
    #     user_choice = preference_result["result"][0].lower()
    #     logging.info(f"ğŸµ ç”¨æˆ·éŸ³ä¹åå¥½é€‰æ‹©: {user_choice}")
        
    #     # è§£æç”¨æˆ·é€‰æ‹©
    #     if any(keyword in user_choice for keyword in ["ç­‰å¾…", "ç­‰", "å®Œæˆ", "æ’­æ”¾å®Œ","æ˜¯çš„","æ²¡é”™","å¥½","å¥½çš„","æ¥ç€","å¬","æ”¾"]):
    #         return "wait"
    #     elif any(keyword in user_choice for keyword in ["ç«‹å³", "ç»§ç»­", "é©¬ä¸Š", "ç°åœ¨","æé—®","å¿«","æ¨è¿›"]):
    #         return "immediate"
    #     elif any(keyword in user_choice for keyword in ["ä¸ç¡®å®š", "ä¸çŸ¥é“", "éšä¾¿", "éƒ½è¡Œ", "éƒ½å¯ä»¥","çŸ¥é“"]):
    #         return "uncertain"
    #     else:
    #         return "uncertain"

    async def handle_music_interaction(self, music_intent):
        """å¤„ç†éŸ³ä¹ç›¸å…³çš„äº¤äº’é€»è¾‘"""
        # ä½¿ç”¨qaæ¨¡å‹å¤„ç†éŸ³ä¹æŒ‡ä»¤
        result = await self.qa.handle_music_command(music_intent)
        
        logging.info(f"ğŸµ éŸ³ä¹æ“ä½œç»“æœ: {result}")
        
        # è®°å½•å¯¹è¯
        response_time = time.time() - self.current_question_start_time
        question = music_intent.get("song_name", "éŸ³ä¹æ“ä½œ")
        await self.conversation_manager.add_conversation_entry(question, result, response_time)
        await self.conversation_manager.save_tracking_data()
        
        # å¤„ç†æ’­æ”¾å‘½ä»¤ - è¿›å…¥éŸ³ä¹æ¨¡å¼
        if music_intent.get("command") == "æ’­æ”¾":
            # æ’­æ”¾éŸ³ä¹æ“ä½œç»“æœ
            if result:
                clean_result = result.strip()
                await self.tts.speak_text(f"{clean_result}", wait=True)
            
            # è¿›å…¥éŸ³ä¹æ¨¡å¼
            self.music_interaction_mode = "music_mode"
            logging.info("ğŸµ å·²è¿›å…¥éŸ³ä¹æ¨¡å¼ï¼Œå°†æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡è¯­éŸ³å‘½ä»¤")
            
            # å¯åŠ¨éŸ³ä¹ç›‘å¬ä»»åŠ¡
            self.music_listen_task = asyncio.create_task(self.music_mode_listening())
            # å¤„ç†æ’­æ”¾åˆ—è¡¨å‘½ä»¤ - åªæ‰“å°ä¸è¯»å‡º
        elif music_intent.get("command") == "æ’­æ”¾åˆ—è¡¨":
            if result:
                clean_result = result.strip()
                # åªæ‰“å°åˆ°æ§åˆ¶å°ï¼Œä¸è¿›è¡Œè¯­éŸ³æ’­æŠ¥
                print(f"\nğŸ“‹ å½“å‰æ’­æ”¾åˆ—è¡¨:\n{clean_result}")
                # ç®€çŸ­æç¤ºå·²æ˜¾ç¤ºæ’­æ”¾åˆ—è¡¨
                # await self.tts.speak_text("æ’­æ”¾åˆ—è¡¨å·²æ˜¾ç¤º", wait=True)
        
        # å¤„ç†æš‚åœå‘½ä»¤ - æš‚åœåè‡ªåŠ¨è¿›å…¥é—®ç­”æ¨¡å¼
        elif music_intent.get("command") == "æš‚åœ":
            # æ’­æ”¾æ“ä½œç»“æœ
            if result:
                clean_result = result.strip()
                await self.tts.speak_text(f"{clean_result}", wait=True)
            
            # éŸ³ä¹å·²æš‚åœï¼Œåˆ‡æ¢åˆ°æ™®é€šé—®ç­”æ¨¡å¼
            self.music_interaction_mode = "normal"
            logging.info("ğŸµ éŸ³ä¹å·²æš‚åœï¼Œåˆ‡æ¢åˆ°é—®ç­”æ¨¡å¼")
        
        # å¤„ç†ç»§ç»­æ’­æ”¾å‘½ä»¤ - ä»é—®ç­”æ¨¡å¼è¿”å›éŸ³ä¹æ¨¡å¼
        elif music_intent.get("command") == "ç»§ç»­":
            # æ’­æ”¾æ“ä½œç»“æœ
            if result:
                clean_result = result.strip()
                await self.tts.speak_text(f"{clean_result}", wait=True)
            
            # é‡æ–°è¿›å…¥éŸ³ä¹æ¨¡å¼
            self.music_interaction_mode = "music_mode"
            logging.info("ğŸµ éŸ³ä¹ç»§ç»­æ’­æ”¾ï¼Œé‡æ–°è¿›å…¥éŸ³ä¹æ¨¡å¼")
            
            # å¯åŠ¨éŸ³ä¹ç›‘å¬ä»»åŠ¡
            self.music_listen_task = asyncio.create_task(self.music_mode_listening())
        
        # å…¶ä»–éŸ³ä¹å‘½ä»¤ - ä»…æ’­æ”¾ç»“æœï¼Œä¿æŒå½“å‰æ¨¡å¼
        else:
            if result:
                clean_result = result.strip()
                # await self.tts.speak_text(f"{clean_result}", wait=True)
                logging.info(f"ğŸµ éŸ³ä¹æ“ä½œç»“æœ: {clean_result}")
        return True
    
    async def music_mode_listening(self):
        """éŸ³ä¹æ¨¡å¼ï¼šæ— é—´éš™æŒç»­ç›‘å¬ç”¨æˆ·æŒ‡ä»¤"""
        try:
            logging.info("ğŸµ å¼€å§‹æ— é—´éš™éŸ³ä¹æ¨¡å¼ç›‘å¬")
            
            while self.music_interaction_mode == "music_mode" and not self.shutdown_event.is_set():
                # æ£€æŸ¥æ’­æ”¾å™¨çŠ¶æ€
                player_status = self.qa.get_player_status()
                if player_status == "stopped":
                    # éŸ³ä¹æ’­æ”¾å®Œæ¯•ï¼Œè‡ªåŠ¨é€€å‡ºéŸ³ä¹æ¨¡å¼
                    logging.info("ğŸµ éŸ³ä¹æ’­æ”¾å·²ç»“æŸï¼Œé€€å‡ºéŸ³ä¹æ¨¡å¼")
                    self.music_interaction_mode = "normal"
                    await self.tts.speak_text("éŸ³ä¹æ’­æ”¾å·²ç»“æŸã€‚", wait=True)
                    break
                
                # ç›´æ¥å¼€å§‹è¯­éŸ³è¯†åˆ« - ä¸æ¸…ç†ç¼“å†²åŒº
                # è¿™ç¡®ä¿æˆ‘ä»¬å§‹ç»ˆåœ¨ç›‘å¬ï¼Œæ— ç›²åŒº
                logging.info("ğŸµ æŒç»­ç›‘å¬éŸ³ä¹å‘½ä»¤ä¸­...")
                command_result = self.asr.real_time_recognition()
                
                # å¤„ç†ä»»ä½•æ£€æµ‹åˆ°çš„å‘½ä»¤
                if (command_result and 
                    'result' in command_result and 
                    command_result['result'] and 
                    len(command_result['result']) > 0 and 
                    command_result['result'][0].strip()):
                    
                    command = command_result["result"][0]
                    logging.info(f"ğŸµ éŸ³ä¹æ¨¡å¼ä¸­æ£€æµ‹åˆ°æŒ‡ä»¤: {command}")
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºéŸ³ä¹ç›¸å…³æŒ‡ä»¤
                    music_intent = self.qa.detect_music_intent(command)
                    if music_intent:
                        # è®°å½•å¼€å§‹æ—¶é—´
                        self.current_question_start_time = time.time()
                        
                        # å¤„ç†éŸ³ä¹æŒ‡ä»¤
                        result = await self.qa.handle_music_command(music_intent)
                        
                        # è®°å½•å¯¹è¯
                        response_time = time.time() - self.current_question_start_time
                        question = music_intent.get("song_name", "éŸ³ä¹æ“ä½œ")
                        await self.conversation_manager.add_conversation_entry(question, result, response_time)
                        await self.conversation_manager.save_tracking_data()
                        
                        # æ’­æ”¾æ“ä½œç»“æœ
                        if result:
                            clean_result = result.replace( "").strip()
                            await self.tts.speak_text(f"{clean_result}", wait=True)
                        
                        # ç‰¹æ®Šå‘½ä»¤å¤„ç†
                        if music_intent.get("command") in ["æš‚åœ", "åœæ­¢", "é€€å‡º"]:
                            # é€€å‡ºéŸ³ä¹æ¨¡å¼
                            self.music_interaction_mode = "normal"
                            logging.info(f"ğŸµ ç”±äº{music_intent.get('command')}å‘½ä»¤é€€å‡ºéŸ³ä¹æ¨¡å¼")
                            break
                    else:
                        # ééŸ³ä¹å‘½ä»¤ï¼Œå¿½ç•¥å¤„ç†
                        logging.info("ğŸµ åœ¨éŸ³ä¹æ¨¡å¼ä¸­æ£€æµ‹åˆ°ééŸ³ä¹å‘½ä»¤ï¼Œå¿½ç•¥å¤„ç†")
                
                # ä¸åœ¨è¯†åˆ«å¾ªç¯ä¹‹é—´æ·»åŠ ä»»ä½•å»¶è¿Ÿ
                # ç«‹å³å¼€å§‹ä¸‹ä¸€æ¬¡è¯†åˆ«ï¼Œå®ç°æ— é—´éš™ç›‘å¬
                
        except asyncio.CancelledError:
            logging.info("ğŸµ éŸ³ä¹ç›‘å¬ä»»åŠ¡è¢«å–æ¶ˆ")
        except Exception as e:
            logging.error(f"ğŸµ éŸ³ä¹ç›‘å¬ä»»åŠ¡å‡ºé”™: {e}")
            # å‘ç”Ÿé”™è¯¯æ—¶æ¢å¤åˆ°æ­£å¸¸æ¨¡å¼
            self.music_interaction_mode = "normal"

    # async def continuous_music_listening(self):
    #     """åœ¨éŸ³ä¹æ’­æ”¾è¿‡ç¨‹ä¸­æŒç»­ç›‘å¬ç”¨æˆ·æŒ‡ä»¤"""
    #     try:
    #         logging.info("ğŸµ å¼€å§‹æŒç»­éŸ³ä¹ç›‘å¬æ¨¡å¼")
            
    #         # å¯åŠ¨æŒç»­è¯†åˆ«
    #         recognition_started = False
    #         last_result_time = time.time()
            
    #         while self.music_interaction_mode == "music_listening" and not self.shutdown_event.is_set():
    #             # æ£€æŸ¥æ’­æ”¾å™¨çŠ¶æ€
    #             player_status = self.qa.get_player_status()
    #             if player_status == "stopped" and self.music_interaction_mode == "music_listening":
    #                 # éŸ³ä¹å·²åœæ­¢ï¼Œé€€å‡ºéŸ³ä¹æ¨¡å¼
    #                 logging.info("ğŸµ éŸ³ä¹æ’­æ”¾å·²åœæ­¢ï¼Œé€€å‡ºéŸ³ä¹æ¨¡å¼")
    #                 self.music_interaction_mode = "normal"
    #                 await self.tts.speak_text("éŸ³ä¹æ’­æ”¾å·²ç»“æŸï¼Œé€€å‡ºéŸ³ä¹æ¨¡å¼ã€‚", wait=True)
    #                 break
                
    #             # å¯åŠ¨ASRæŒç»­ç›‘å¬ï¼ˆå¦‚æœå°šæœªå¯åŠ¨ï¼‰
    #             if not recognition_started:
    #                 # æ¸…ç†éŸ³é¢‘ç¼“å†²åŒº
    #                 await self.clear_audio_buffer()
    #                 # å¯åŠ¨æŒç»­ç›‘å¬
    #                 self.asr.start_continuous_recognition()
    #                 recognition_started = True
    #                 logging.info("ğŸµ å·²å¯åŠ¨æŒç»­è¯­éŸ³è¯†åˆ«")
                
    #             # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„è¯†åˆ«ç»“æœï¼ˆçº¦æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡ï¼‰
    #             current_time = time.time()
    #             if current_time - last_result_time >= 5.0:
    #                 # è·å–æœ€æ–°çš„è¯†åˆ«ç»“æœ
    #                 command_result = self.asr.get_latest_recognition_result()
    #                 last_result_time = current_time
                    
    #                 # æ£€æŸ¥è¯­éŸ³è¯†åˆ«ç»“æœ
    #                 if (command_result and 
    #                     'result' in command_result and 
    #                     command_result['result'] and
    #                     len(command_result['result']) > 0 and
    #                     command_result['result'][0] != ""):
                        
    #                     command = command_result["result"][0]
    #                     logging.info(f"ğŸµ éŸ³ä¹æ¨¡å¼ä¸­æ£€æµ‹åˆ°æŒ‡ä»¤: {command}")
                        
    #                     # æ£€æŸ¥æ˜¯å¦ä¸ºéŸ³ä¹ç›¸å…³æŒ‡ä»¤
    #                     music_intent = self.qa.detect_music_intent(command)
    #                     if music_intent:
    #                         # è·å–å¼€å§‹æ—¶é—´
    #                         self.current_question_start_time = time.time()
                            
    #                         # æš‚åœæŒç»­è¯†åˆ«å¤„ç†å‘½ä»¤
    #                         self.asr.pause_continuous_recognition()
                            
    #                         # å¤„ç†éŸ³ä¹æŒ‡ä»¤
    #                         result = await self.qa.handle_music_command(music_intent)
                            
    #                         # è®°å½•å¯¹è¯
    #                         response_time = time.time() - self.current_question_start_time
    #                         question = music_intent.get("song_name", "éŸ³ä¹æ“ä½œ")
    #                         await self.conversation_manager.add_conversation_entry(question, result, response_time)
    #                         await self.conversation_manager.save_tracking_data()
                            
    #                         # æ’­æ”¾æ“ä½œç»“æœ
    #                         if result:
    #                             clean_result = result.replace("11", "").strip()
    #                             await self.tts.speak_text(f"{clean_result}", wait=True)
                            
    #                         # å¤„ç†ç‰¹æ®Šå‘½ä»¤
    #                         if music_intent.get("command") == "åœæ­¢" or music_intent.get("command") == "é€€å‡º":
    #                             # é€€å‡ºéŸ³ä¹æ¨¡å¼
    #                             self.music_interaction_mode = "normal"
    #                             await self.tts.speak_text("å·²é€€å‡ºéŸ³ä¹æ¨¡å¼ã€‚", wait=True)
    #                             logging.info("ğŸµ é€šè¿‡åœæ­¢å‘½ä»¤é€€å‡ºéŸ³ä¹æ¨¡å¼")
    #                             break
                            
    #                         # æ¢å¤æŒç»­è¯†åˆ«
    #                         self.asr.resume_continuous_recognition()
    #                         recognition_started = True
                    
    #             # çŸ­æš‚ä¼‘çœ ä»¥å‡å°‘CPUä½¿ç”¨
    #             await asyncio.sleep(0.1)
            
    #         # åœæ­¢æŒç»­è¯†åˆ«
    #         if recognition_started:
    #             self.asr.stop_continuous_recognition()
    #             logging.info("ğŸµ å·²åœæ­¢æŒç»­è¯­éŸ³è¯†åˆ«")
            
    #     except asyncio.CancelledError:
    #         logging.info("ğŸµ éŸ³ä¹ç›‘å¬ä»»åŠ¡è¢«å–æ¶ˆ")
    #         # ç¡®ä¿åœæ­¢æŒç»­è¯†åˆ«
    #         self.asr.stop_continuous_recognition()
    #     except Exception as e:
    #         logging.error(f"ğŸµ éŸ³ä¹ç›‘å¬ä»»åŠ¡å‡ºé”™: {e}")
    #         # ç¡®ä¿åœæ­¢æŒç»­è¯†åˆ«
    #         self.asr.stop_continuous_recognition()
    #         # æ¢å¤æ­£å¸¸æ¨¡å¼
    #         self.music_interaction_mode = "normal"

    # async def music_timer_reminder(self):
    #     try:
    #         await asyncio.sleep(60)
            
    #         # å®šæ—¶å™¨å®Œæˆåä¸ç›´æ¥åˆ‡æ¢åˆ°normalæ¨¡å¼ï¼Œè€Œæ˜¯å†æ¬¡è¯¢é—®ç”¨æˆ·åå¥½
    #         if not self.shutdown_event.is_set() and self.music_interaction_mode == "timer_waiting":
    #             # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­ç­‰å¾…è¿˜æ˜¯å¼€å§‹æé—®
    #             await self.tts.speak_text("éŸ³ä¹æ­£åœ¨æ’­æ”¾ï¼Œæ‚¨å¸Œæœ›ç­‰å¾…æ’­æ”¾å®Œæˆå†é—®é—®é¢˜ï¼Œè¿˜æ˜¯ç°åœ¨å°±å¼€å§‹æé—®ï¼Ÿ", wait=True)
                
    #             # æ¸…ç†éŸ³é¢‘ç¼“å†²åŒº
    #             await self.clear_audio_buffer()
                
    #             # æ˜¾ç¤ºç›‘å¬æŒ‡ç¤ºå™¨
    #             self.animation_manager.start_animation("æ­£åœ¨è†å¬æ‚¨çš„é€‰æ‹©")
                
    #             # è·å–ç”¨æˆ·å›ç­”
    #             preference_result = self.asr.real_time_recognition()
    #             self.animation_manager.stop_current()
                
    #             if not preference_result or 'result' not in preference_result or not preference_result['result']:
    #                 logging.info("âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆå›ç­”ï¼Œç»§ç»­ç­‰å¾…")
    #                 # å¦‚æœæ²¡æœ‰æœ‰æ•ˆå›ç­”ï¼Œç»§ç»­ç­‰å¾…
    #                 self.music_timer_task = asyncio.create_task(self.music_timer_reminder())
    #                 return
                
    #             user_choice = preference_result["result"][0].lower()
    #             logging.info(f"ğŸµ ç”¨æˆ·éŸ³ä¹åå¥½é€‰æ‹©: {user_choice}")
                
    #             # è§£æç”¨æˆ·é€‰æ‹©
    #             if any(keyword in user_choice for keyword in ["ç­‰å¾…", "ç­‰", "å®Œæˆ", "æ’­æ”¾å®Œ", "æ˜¯çš„", "æ²¡é”™", "å¥½", "å¥½çš„"]):
    #                 self.music_interaction_mode = "waiting"
    #                 await self.tts.speak_text("å¥½çš„ï¼Œå°†ç­‰å¾…éŸ³ä¹æ’­æ”¾å®Œæˆåå†ç»§ç»­ã€‚", wait=True)
    #                 logging.info("ğŸµ è®¾ç½®æ¨¡å¼: ç­‰å¾…éŸ³ä¹æ’­æ”¾å®Œæˆ")
    #             elif any(keyword in user_choice for keyword in ["ç«‹å³", "ç»§ç»­", "é©¬ä¸Š", "ç°åœ¨", "æé—®", "å¿«", "æ¨è¿›"]):
    #                 self.music_interaction_mode = "real_time"
    #                 await self.tts.speak_text("å¥½çš„ï¼Œæ‚¨å¯ä»¥éšæ—¶å‘å‡ºè¯­éŸ³æŒ‡ä»¤ã€‚", wait=True)
    #                 logging.info("ğŸµ è®¾ç½®æ¨¡å¼: å®æ—¶äº¤äº’")
    #             elif any(keyword in user_choice for keyword in ["ä¸ç¡®å®š", "ä¸çŸ¥é“", "éšä¾¿", "éƒ½è¡Œ", "éƒ½å¯ä»¥"]):
    #                 # ç»§ç»­ä½¿ç”¨timer_waitingæ¨¡å¼å¹¶é‡å¯å®šæ—¶å™¨
    #                 self.music_timer_task = asyncio.create_task(self.music_timer_reminder())
    #                 await self.tts.speak_text("å¥½çš„ï¼Œå°†åœ¨ä¸€åˆ†é’Ÿåå†æ¬¡è¯¢é—®ã€‚", wait=True)
    #                 logging.info("ğŸµ è®¾ç½®æ¨¡å¼: ç»§ç»­å®šæ—¶æé†’")
    #             else:
    #                 # é»˜è®¤ä¿æŒå½“å‰æ¨¡å¼å¹¶é‡å¯å®šæ—¶å™¨
    #                 self.music_timer_task = asyncio.create_task(self.music_timer_reminder())
    #                 await self.tts.speak_text("å¥½çš„ï¼Œå°†åœ¨ä¸€åˆ†é’Ÿåå†æ¬¡è¯¢é—®ã€‚", wait=True)
    #                 logging.info("ğŸµ è®¾ç½®æ¨¡å¼: ç»§ç»­å®šæ—¶æé†’")
    #     except asyncio.CancelledError:
    #         logging.info("ğŸµ å®šæ—¶æé†’ä»»åŠ¡è¢«å–æ¶ˆ")
    #     except Exception as e:
    #         logging.error(f"ğŸµ å®šæ—¶æé†’ä»»åŠ¡å‡ºé”™: {e}")

    async def process_user_input(self):
        """å¤„ç†ç”¨æˆ·è¯­éŸ³è¾“å…¥"""
        logging.info("\nğŸ¤ ç­‰å¾…è¯­éŸ³æ’­æ”¾å®ŒğŸ¤")
        
        # ç¡®ä¿TTSå®Œå…¨ç»“æŸ
        await self.tts.wait_until_done()
        
        # æ¸…ç©ºéŸ³é¢‘ç¼“å†²åŒº
        await self.clear_audio_buffer()
        
        # æ ¹æ®å½“å‰æ¨¡å¼è¿›è¡Œå¤„ç†
        if self.music_interaction_mode == "normal":
            # æ­£å¸¸é—®ç­”æ¨¡å¼ï¼šæç¤ºç”¨æˆ·é—®é¢˜
            prompt_text = "è¯·é—®æ‚¨æœ‰ä»€ä¹ˆå…³äºè†³é£Ÿå’Œå¥åº·çš„é—®é¢˜ï¼Ÿ" if self.first_interaction else random.choice(self.follow_up_prompts)
            self.first_interaction = False
            
            try:
                await self.tts.speak_text(prompt_text, wait=True)
            except Exception as e:
                logging.error(f"âš ï¸ è¯­éŸ³æç¤ºå¤±è´¥: {e}")
                print(prompt_text)
            
            await asyncio.sleep(0.3)
            await self.clear_audio_buffer()
            
            # æ˜¾ç¤ºç›‘å¬æŒ‡ç¤ºå™¨
            self.animation_manager.start_animation("æ­£åœ¨è†å¬")
            
            # æ‰§è¡Œè¯­éŸ³è¯†åˆ«
            question_result = self.asr.real_time_recognition()
            
            # åœæ­¢ç›‘å¬æŒ‡ç¤ºå™¨
            self.animation_manager.stop_current()
            
        elif self.music_interaction_mode == "music_mode":
            # éŸ³ä¹æ¨¡å¼ï¼šè·³è¿‡æé—®ï¼Œäº¤ç”±music_mode_listeningå¤„ç†
            await asyncio.sleep(0.5)
            return None
        
        # æ£€æŸ¥è¯­éŸ³è¯†åˆ«ç»“æœ
        if (not question_result or 
            'result' not in question_result or 
            not question_result['result'] or  
            len(question_result['result']) == 0 or  
            question_result['result'][0] == "" or  
            question_result['result'][0] in [
                "å—¯å—¯ã€‚", "å—¯å—¯å—¯å—¯ã€‚", "å—¯å—¯å—¯ã€‚", "å•Šï¼Ÿ","å—¯å—¯å—¯å—¯å—¯ã€‚","å—¯å—¯å—¯å—¯å—¯å—¯ã€‚","å—¯å—¯å—¯å—¯å—¯å—¯å—¯ã€‚" 
            ]):
            logging.info("âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³è¾“å…¥")
            print("âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³è¾“å…¥")
            
            # ä¸è¿›è¡ŒTTSæç¤ºï¼Œç›´æ¥ç­‰å¾…10ç§’åç»§ç»­
            logging.info("ğŸ•™ ç­‰å¾…10ç§’åç»§ç»­ç›‘å¬...")
            await asyncio.sleep(10)
            return None
            
        question = question_result["result"][0] 
        logging.info(f"ğŸ’¬ é—®é¢˜: {question}")
        self.current_question_start_time = time.time()

        # å¤„ç†é€€å‡ºå‘½ä»¤
        if any(word in question.lower() for word in ["æ‹œæ‹œ", "å†è§", "é€€å‡º"]):
            logging.info("="*80)
            logging.info(f"ğŸšª æ”¶åˆ°é€€å‡ºå‘½ä»¤: '{question}'")
            logging.info("="*80)
            
            # å–æ¶ˆéŸ³ä¹ç›‘å¬ä»»åŠ¡
            if hasattr(self, 'music_listen_task') and self.music_listen_task and not self.music_listen_task.done():
                self.music_listen_task.cancel()
            
            try:
                await self.tts.speak_text("å¥½çš„ï¼Œæ„Ÿè°¢ä½¿ç”¨ä¸­åŒ»åº·å…»å’Œè†³é£Ÿä¸“å®¶çŸ¥è¯†åŠ©æ‰‹ï¼Œå†è§ï¼", wait=True)
            except:
                print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ä¸­åŒ»åº·å…»å’Œè†³é£ŸçŸ¥è¯†åŠ©æ‰‹ï¼Œå†è§ï¼")
                
            self.shutdown_event.set()
            return None

        # å¤„ç†éŸ³ä¹ç›¸å…³æŒ‡ä»¤
        if question:
            music_intent = self.qa.detect_music_intent(question)
            if music_intent:
                # å–æ¶ˆä¹‹å‰çš„éŸ³ä¹ç›‘å¬ä»»åŠ¡
                if hasattr(self, 'music_listen_task') and self.music_listen_task and not self.music_listen_task.done():
                    self.music_listen_task.cancel()
                
                # æ˜¾ç¤ºå¤„ç†åŠ¨ç”»
                self.animation_manager.start_animation("æ­£åœ¨å¤„ç†éŸ³ä¹è¯·æ±‚")
                
                try:
                    await self.handle_music_interaction(music_intent)
                finally:
                    self.animation_manager.stop_current()
                
                return None

        # å¦‚æœä¸æ˜¯éŸ³ä¹å‘½ä»¤ï¼Œç»§ç»­å¤„ç†ä¸ºæ™®é€šé—®ç­”
        return question

    async def process_streaming_answer(self, question):
        """å¤„ç†æµå¼å›ç­”å¹¶åŒæ­¥è¿›è¡Œè¯­éŸ³åˆæˆ"""
        # æ–‡æœ¬ç¼“å†²åŒº
        text_buffer = ""
        # è®¡ç®—ç¼“å†²åŒºä¸­æ ‡ç‚¹ç¬¦å·çš„æ•°é‡
        punctuation_count = 0
        # è®¾ç½®æ ‡ç‚¹ç¬¦å·é˜ˆå€¼ï¼Œè¾¾åˆ°è¿™ä¸ªæ•°é‡æ‰å‘é€
        punctuation_threshold = 2  # å¯ä»¥è°ƒæ•´ä¸º3æˆ–4
        
        # é‡ç½®å½“å‰ç­”æ¡ˆ
        self.current_answer = ""
        
        # æ˜¾ç¤ºæ€è€ƒåŠ¨ç”»
        self.animation_manager.start_animation("æ­£åœ¨æ€è€ƒ")
        
        first_chunk = True
        search_animation_started = False
        
        try:
            # æµå¼ç”Ÿæˆå›ç­”å¹¶åŒæ­¥è¿›è¡Œè¯­éŸ³åˆæˆ
            async for chunk in self.qa.ask_stream(question):
                # å¤„ç†æœç´¢æç¤º
                if first_chunk and chunk.startswith("å®Œæˆï¼"):
                    await self.tts.speak_text("æ­£åœ¨å¼€å¯ç½‘ç»œæœç´¢ä»»åŠ¡", wait=True)
                    # await asyncio.sleep(0.5)
                    # åˆ‡æ¢åˆ°æœç´¢åŠ¨ç”»ï¼Œåªåˆ‡æ¢ä¸€æ¬¡
                    if not search_animation_started:
                        self.animation_manager.start_animation("æ‰§è¡Œç½‘ç»œæœç´¢")
                        search_animation_started = True
                    first_chunk = False
                    continue
                else:
                    if first_chunk:
                        # åœæ­¢æ€è€ƒåŠ¨ç”»ï¼Œå¼€å§‹è¾“å‡ºç­”æ¡ˆ
                        self.animation_manager.stop_current()
                        print(f"\nğŸ’¡ {self.recognized_user}ï¼Œå…³äº'{question}'ï¼Œ")
                        first_chunk = False


            async for chunk in self.qa.ask_stream(question):
                # å¤„ç†æœç´¢æç¤º
                if first_chunk and chunk.startswith("å¥½äº†"):
                    await self.tts.speak_text("æ­£åœ¨è¿›è¡Œæ‹ç…§è¯†åˆ«", wait=True)
                    # await asyncio.sleep(0.5)
                    # åˆ‡æ¢åˆ°æœç´¢åŠ¨ç”»ï¼Œåªåˆ‡æ¢ä¸€æ¬¡
                    if not search_animation_started:
                        self.animation_manager.start_animation("æ‹ç…§è¯†åˆ«")
                        search_animation_started = True
                    first_chunk = False
                    continue
                else:
                    if first_chunk:
                        # åœæ­¢æ€è€ƒåŠ¨ç”»ï¼Œå¼€å§‹è¾“å‡ºç­”æ¡ˆ
                        self.animation_manager.stop_current()
                        print(f"\nğŸ’¡ {self.recognized_user}ï¼Œå…³äº'{question}'ï¼Œ")
                        first_chunk = False
   
                
                # ç´¯ç§¯ç­”æ¡ˆ
                self.current_answer += chunk
                # å®æ—¶æ˜¾ç¤ºæ–‡å­—ï¼ˆä¸æ¢è¡Œï¼‰
                print(chunk, end="", flush=True)
                
                # å°†æ–°å—æ·»åŠ åˆ°ç¼“å†²åŒº
                text_buffer += chunk
                
                # è®¡ç®—å½“å‰å—ä¸­çš„æ ‡ç‚¹ç¬¦å·æ•°é‡
                new_punctuations = len(re.findall(r'[ã€‚.!?ï¼ï¼Ÿ;ï¼›]', chunk))
                punctuation_count += new_punctuations
                
                # æ¡ä»¶ï¼šè¾¾åˆ°æ ‡ç‚¹ç¬¦å·é˜ˆå€¼æˆ–ç¼“å†²åŒºè¶³å¤Ÿé•¿
                if (punctuation_count >= punctuation_threshold and len(text_buffer) >= 25) or len(text_buffer) > 80:
                    if text_buffer.strip():
                        # å¼‚æ­¥å‘é€åˆ°TTSï¼Œä¸ç­‰å¾…
                        await self.tts.speak_text(text_buffer, wait=False)
                    
                    # é‡ç½®ç¼“å†²åŒºå’Œè®¡æ•°å™¨
                    text_buffer = ""
                    punctuation_count = 0
                
                # ç»™UIæ¸²æŸ“çš„æ—¶é—´
                await asyncio.sleep(0.01)
            
            # å¤„ç†å‰©ä½™çš„æ–‡æœ¬ç¼“å†²åŒº
            if text_buffer.strip():
                await self.tts.speak_text(text_buffer, wait=False)
            
            print()  # æ¢è¡Œ
            
            # ç­‰å¾…æ‰€æœ‰è¯­éŸ³æ’­æ”¾å®Œæˆ
            await self.tts.wait_until_done()
            
            # è®°å½•å¯¹è¯
            response_time = time.time() - self.current_question_start_time
            await self.conversation_manager.add_conversation_entry(question, self.current_answer, response_time)
            await self.conversation_manager.save_tracking_data()
            
        except Exception as e:
            # ç¡®ä¿åœæ­¢åŠ¨ç”»
            self.animation_manager.stop_current()
            logging.error(f"âŒ å¤„ç†æµå¼å›ç­”æ—¶å‡ºé”™: {e}")
            print(f"\nâŒ å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {e}")
            
    async def run(self):
        """è¿è¡Œä¸»å¾ªç¯"""
        # é¦–å…ˆè¿›è¡Œäººè„¸è®¤è¯
        self.face_auth_success, self.recognized_user = await self.authenticate_user()
        
        # å¦‚æœäººè„¸è®¤è¯å¤±è´¥ï¼Œé€€å‡ºç¨‹åº
        if not self.face_auth_success:
            return
            
        # äººè„¸è®¤è¯æˆåŠŸåï¼Œåˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶
        if not await self.initialize():
            return
            
        self.setup_signal_handlers()
        
        # å¯åŠ¨æç¤º
        print("\n" + "â•" * 80)
        print(f"{'ğŸŒŸ ä¸­åŒ»åº·å…»å’Œè†³é£ŸçŸ¥è¯†é—®ç­”ç³»ç»Ÿå·²å¯åŠ¨ ğŸŒŸ':^80}")
        print(f"{'ğŸ‘¤ ç”¨æˆ·: ' + self.recognized_user:^80}")
        print(f"{'âŒ¨ï¸  æŒ‰ Ctrl+C é€€å‡º':^80}")
        print("â•" * 80 + "\n")
        
        try:
            # åˆå§‹æ¬¢è¿è¯­
            try:
                await self.tts.speak_text(f"{self.recognized_user}ï¼Œä¸­åŒ»åº·å…»å’Œè†³é£ŸçŸ¥è¯†é—®ç­”ç³»ç»Ÿå·²å¯åŠ¨ã€‚", wait=True)
                await asyncio.sleep(0.5)
                await self.clear_audio_buffer()
            except Exception as e:
                logging.error(f"âš ï¸ æ’­æ”¾æ¬¢è¿æ¶ˆæ¯å¤±è´¥: {e}")
                print(f"ğŸ‘‹ {self.recognized_user}ï¼Œä¸­åŒ»åº·å…»å’Œè†³é£ŸçŸ¥è¯†é—®ç­”ç³»ç»Ÿå·²å¯åŠ¨ã€‚")

            while not self.shutdown_event.is_set():
                # è·å–ç”¨æˆ·é—®é¢˜
                question = await self.process_user_input()
                
                # æ£€æŸ¥æ˜¯å¦æ”¶åˆ°é€€å‡ºä¿¡å·
                if self.shutdown_event.is_set():
                    break
                
                # å¤„ç†é—®é¢˜å¹¶å›ç­”
                if question:
                    # ä½¿ç”¨æ–°çš„æµå¼å¤„ç†æ–¹æ³•
                    await self.process_streaming_answer(question)
                    
        except KeyboardInterrupt:
            logging.info("âŒ¨ï¸ æ”¶åˆ°é”®ç›˜ä¸­æ–­ä¿¡å·")
            print("\nâŒ¨ï¸ æ”¶åˆ°é”®ç›˜ä¸­æ–­ä¿¡å·")
            self.shutdown_event.set()
        except asyncio.CancelledError:
            logging.info("ğŸ›‘ ä»»åŠ¡è¢«å–æ¶ˆ")
            print("\nğŸ›‘ ä»»åŠ¡è¢«å–æ¶ˆ")
            self.shutdown_event.set()
        except Exception as e:
            logging.error(f"âŒ è¿è¡Œæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            print(f"\nâŒ è¿è¡Œæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            # å–æ¶ˆå®šæ—¶å™¨ä»»åŠ¡
            if self.music_timer_task and not self.music_timer_task.done():
                self.music_timer_task.cancel()
            # åœæ­¢æ‰€æœ‰åŠ¨ç”»
            self.animation_manager.stop_current()
            # æ¸…ç†èµ„æº
            await self.shutdown()
            
    async def shutdown(self):
        """æ¸…ç†èµ„æºå¹¶å…³é—­ç³»ç»Ÿ"""
        logging.info("ğŸ§¹ æ­£åœ¨å…³é—­ç³»ç»Ÿ...")
        print("\nğŸ§¹ æ­£åœ¨å…³é—­ç³»ç»Ÿ...")
        
        # æ˜¾ç¤ºå…³é—­åŠ¨ç”»
        self.animation_manager.start_animation("æ­£åœ¨æ¸…ç†ç³»ç»Ÿèµ„æº")
        
        try:
            await self.conversation_manager.save_tracking_data()
            session_summary = self.conversation_manager.get_session_summary()
            logging.info(f"ğŸ“Š ä¼šè¯ç»Ÿè®¡: {session_summary}")
            print(f"\nğŸ“Š ä¼šè¯æ‘˜è¦:")
            print(f"  - ä¼šè¯ID: {session_summary['session_id']}")
            print(f"  - æ€»æ—¶é•¿: {session_summary['duration']}ç§’")
            print(f"  - é—®é¢˜æ•°: {session_summary['total_questions']}")
            print(f"  - å¹³å‡å“åº”æ—¶é—´: {session_summary['avg_response_time']}ç§’")
            print(f"  - é”™è¯¯æ¬¡æ•°: {session_summary['error_count']}")

            if self.tts and not self.shutdown_event.is_set():
                try:
                    await self.tts.speak_text("æ„Ÿè°¢ä½¿ç”¨ä¸­åŒ»åº·å…»å’Œè†³é£ŸçŸ¥è¯†åŠ©æ‰‹å†è§ï¼", wait=True)
                except Exception as e:
                    logging.error(f"âš ï¸ æ’­æ”¾å‘Šåˆ«è¯­éŸ³å¤±è´¥: {e}")
            
            # å…ˆå…³é—­TTS
            if self.tts:
                await self.tts.shutdown()
                
            # å…³é—­ASR
            if self.asr:
                self.asr.stop_recording()
                logging.info("âœ… ASRèµ„æºå·²é‡Šæ”¾")
                
            # åœæ­¢å…³é—­åŠ¨ç”»
            self.animation_manager.stop_current()
                
            logging.info("âœ… æ‰€æœ‰èµ„æºå·²æ¸…ç†ï¼Œç³»ç»Ÿå·²å®‰å…¨å…³é—­")
            print("\n" + "â•" * 80)
            print(f"{'ğŸ‘‹ ç³»ç»Ÿå·²å®‰å…¨å…³é—­ï¼Œæ„Ÿè°¢ä½¿ç”¨ï¼ğŸ‘‹':^80}")
            print("â•" * 80)
            
        except Exception as e:
            # ç¡®ä¿åŠ¨ç”»åœæ­¢
            self.animation_manager.stop_current()
            logging.error(f"âŒ æ¸…ç†èµ„æºæ—¶å‡ºé”™: {e}")
            print(f"\nâŒ æ¸…ç†èµ„æºæ—¶å‡ºé”™: {e}")


async def main():
    """ç¨‹åºå…¥å£ç‚¹"""
    # æ˜¾ç¤ºå¯åŠ¨æ¨ªå¹…
    print("\n" + "â•" * 80)
    print(f"{'ğŸš€ ä¸­åŒ»åº·å…»å’Œè†³é£ŸçŸ¥è¯†é—®ç­”ç³»ç»Ÿ v2.0 ğŸš€':^80}")
    print(f"{'å¯åŠ¨ä¸­...':^80}")
    print("â•" * 80 + "\n")
    
    parser = argparse.ArgumentParser(description="ä¸­åŒ»åº·å…»å’Œè†³é£ŸçŸ¥è¯†é—®ç­”ç³»ç»Ÿ")
    parser.add_argument("--voice", default="zh-CN-XiaoyiNeural", help="TTSè¯­éŸ³")
    parser.add_argument("--debug", action="store_true", help="å¯ç”¨è°ƒè¯•æ¨¡å¼")
    args = parser.parse_args()
    
    try:
        chatbox = SweetPotatoChatbox(
            voice=args.voice,
            debug=args.debug
        )
        await chatbox.run()
    except KeyboardInterrupt:
        print("\nâŒ¨ï¸ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logging.error(f"âŒ ç¨‹åºå‡ºé”™: {e}")
        print(f"\nâŒ ç¨‹åºå‡ºé”™: {e}")
    finally:
        print("\nğŸ‘‹ ç¨‹åºå·²å®Œå…¨é€€å‡º")
        os._exit(0)


if __name__ == "__main__":
    asyncio.run(main())